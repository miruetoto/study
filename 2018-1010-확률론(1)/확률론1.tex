\documentclass[12pt,oneside,english,a4paper]{article}
\usepackage{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{wallpaper}
\usepackage{wrapfig,booktabs}

\usepackage{fancyhdr}

\usepackage{fourier-orns}
\newcommand{\dash}{\noindent \newline\textcolor{black}{\hrulefill~ \raisebox{-2.5pt}[10pt][10pt]{\leafright \decofourleft \decothreeleft  \aldineright \decotwo \floweroneleft \decoone   \floweroneright \decotwo \aldineleft\decothreeright \decofourright \leafleft} ~  \hrulefill}}

\usepackage{titlesec}
\titleformat*{\section}{\it\huge\bfseries}
\titleformat*{\subsection}{\it\huge\bfseries}
\titleformat*{\subsubsection}{\it\LARGE\bfseries}
\titleformat*{\paragraph}{\huge\bfseries}
\titleformat*{\subparagraph}{\LARGE\bfseries}

\usepackage[left=20px,right=20px,top=50px,bottom=50px,paperwidth=8in,paperheight=12in]{geometry}

\usepackage[cjk]{kotex}
\usepackage{amsthm} 
\usepackage{amsmath} 
\usepackage{amsfonts}
\usepackage{enumerate} 
\usepackage{cite}
\usepackage{graphics} 
\usepackage{graphicx,lscape} 
\usepackage{subcaption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{titlesec}
\usepackage{cite, url}
\usepackage{amssymb}

\def\bk{\paragraph{\Large$$}\Large}
\def\ck{\paragraph{\Large$\bullet$}\Large}
\def\sol{\paragraph{\Large(sol)}\Large}
\def\pf{\paragraph{\Large(pf)}\Large}
\def\note{\paragraph{\Large\textit{\underline{note:}}}\Large}
\def\ex{\paragraph{\Large\textit{example:}}\Large}
\newcommand{\para}[1]{\paragraph{\Large\it\underline{\textbf{#1:}}}\Large}
\newcommand{\parablue}[1]{\paragraph{\Large\textcolor{blue}{\it\underline{\textbf{#1:}}}}\Large}
\newcommand{\parared}[1]{\paragraph{\Large\textcolor{red}{\it\underline{\textbf{#1:}}}}\Large}


\def\one{\paragraph{\Large(1)}\Large}
\def\two{\paragraph{\Large(2)}\Large}
\def\three{\paragraph{\Large(3)}\Large}
\def\four{\paragraph{\Large(4)}\Large}
\def\five{\paragraph{\Large(5)}\Large}
\def\six{\paragraph{\Large(6)}\Large}
\def\seven{\paragraph{\Large(7)}\Large}
\def\eight{\paragraph{\Large(8)}\Large}
\def\nine{\paragraph{\Large(9)}\Large}
\def\ten{\paragraph{\Large(10)}\Large}

\def\cka{\paragraph{\Large(a)}\Large}
\def\ckb{\paragraph{\Large(b)}\Large}
\def\ckc{\paragraph{\Large(c)}\Large}
\def\ckd{\paragraph{\Large(d)}\Large}
\def\cke{\paragraph{\Large(e)}\Large}
\def\ckf{\paragraph{\Large(f)}\Large}
\def\ckg{\paragraph{\Large(g)}\Large}
\def\ckh{\paragraph{\Large(h)}\Large}
\def\cki{\paragraph{\Large(i)}\Large}
\def\ckj{\paragraph{\Large(j)}\Large}

\newcommand{\bs}[1]{\mbox{\boldmath $#1$}}

\newcommand{\bsa}{\mbox{\boldmath $a$}}
\newcommand{\bsb}{\mbox{\boldmath $b$}}
\newcommand{\bsc}{\mbox{\boldmath $c$}}
\newcommand{\bsd}{\mbox{\boldmath $d$}}
\newcommand{\bse}{\mbox{\boldmath $e$}}
\newcommand{\bsf}{\mbox{\boldmath $f$}}
\newcommand{\bsg}{\mbox{\boldmath $g$}}
\newcommand{\bsh}{\mbox{\boldmath $h$}}
\newcommand{\bsi}{\mbox{\boldmath $i$}}
\newcommand{\bsj}{\mbox{\boldmath $j$}}
\newcommand{\bsk}{\mbox{\boldmath $k$}}
\newcommand{\bsl}{\mbox{\boldmath $l$}}
\newcommand{\bsm}{\mbox{\boldmath $m$}}
\newcommand{\bsn}{\mbox{\boldmath $n$}}
\newcommand{\bso}{\mbox{\boldmath $o$}}
\newcommand{\bsp}{\mbox{\boldmath $p$}}
\newcommand{\bsq}{\mbox{\boldmath $q$}}
\newcommand{\bsr}{\mbox{\boldmath $r$}}
\newcommand{\bss}{\mbox{\boldmath $s$}}
\newcommand{\bst}{\mbox{\boldmath $t$}}
\newcommand{\bsu}{\mbox{\boldmath $u$}}
\newcommand{\bsv}{\mbox{\boldmath $v$}}
\newcommand{\bsw}{\mbox{\boldmath $w$}}
\newcommand{\bsx}{\mbox{\boldmath $x$}}
\newcommand{\bsy}{\mbox{\boldmath $y$}}
\newcommand{\bsz}{\mbox{\boldmath $z$}}

\newcommand{\bfa}{\mbox{$\bf{a}$}}
\newcommand{\bfb}{\mbox{$\bf{b}$}}
\newcommand{\bfc}{\mbox{$\bf{c}$}}
\newcommand{\bfd}{\mbox{$\bf{d}$}}
\newcommand{\bfe}{\mbox{$\bf{e}$}}
\newcommand{\bff}{\mbox{$\bf{f}$}}
\newcommand{\bfg}{\mbox{$\bf{g}$}}
\newcommand{\bfh}{\mbox{$\bf{h}$}}
\newcommand{\bfi}{\mbox{$\bf{i}$}}
\newcommand{\bfj}{\mbox{$\bf{j}$}}
\newcommand{\bfk}{\mbox{$\bf{k}$}}
\newcommand{\bfl}{\mbox{$\bf{l}$}}
\newcommand{\bfm}{\mbox{$\bf{m}$}}
\newcommand{\bfn}{\mbox{$\bf{n}$}}
\newcommand{\bfo}{\mbox{$\bf{o}$}}
\newcommand{\bfp}{\mbox{$\bf{p}$}}
\newcommand{\bfq}{\mbox{$\bf{q}$}}
\newcommand{\bfr}{\mbox{$\bf{r}$}}
\newcommand{\bfs}{\mbox{$\bf{s}$}}
\newcommand{\bft}{\mbox{$\bf{t}$}}
\newcommand{\bfu}{\mbox{$\bf{u}$}}
\newcommand{\bfv}{\mbox{$\bf{v}$}}
\newcommand{\bfw}{\mbox{$\bf{w}$}}
\newcommand{\bfx}{\mbox{$\bf{x}$}}
\newcommand{\bfy}{\mbox{$\bf{y}$}}
\newcommand{\bfz}{\mbox{$\bf{z}$}}

\newcommand{\bsA}{\mbox{\boldmath $A$}}
\newcommand{\bsB}{\mbox{\boldmath $B$}}
\newcommand{\bsC}{\mbox{\boldmath $C$}}
\newcommand{\bsD}{\mbox{\boldmath $D$}}
\newcommand{\bsE}{\mbox{\boldmath $E$}}
\newcommand{\bsF}{\mbox{\boldmath $F$}}
\newcommand{\bsG}{\mbox{\boldmath $G$}}
\newcommand{\bsH}{\mbox{\boldmath $H$}}
\newcommand{\bsI}{\mbox{\boldmath $I$}}
\newcommand{\bsJ}{\mbox{\boldmath $J$}}
\newcommand{\bsK}{\mbox{\boldmath $K$}}
\newcommand{\bsL}{\mbox{\boldmath $L$}}
\newcommand{\bsM}{\mbox{\boldmath $M$}}
\newcommand{\bsN}{\mbox{\boldmath $N$}}
\newcommand{\bsO}{\mbox{\boldmath $O$}}
\newcommand{\bsP}{\mbox{\boldmath $P$}}
\newcommand{\bsQ}{\mbox{\boldmath $Q$}}
\newcommand{\bsR}{\mbox{\boldmath $R$}}
\newcommand{\bsS}{\mbox{\boldmath $S$}}
\newcommand{\bsT}{\mbox{\boldmath $T$}}
\newcommand{\bsU}{\mbox{\boldmath $U$}}
\newcommand{\bsV}{\mbox{\boldmath $V$}}
\newcommand{\bsW}{\mbox{\boldmath $W$}}
\newcommand{\bsX}{\mbox{\boldmath $X$}}
\newcommand{\bsY}{\mbox{\boldmath $Y$}}
\newcommand{\bsZ}{\mbox{\boldmath $Z$}}

\newcommand{\bfA}{\mbox{$\bf{A}$}}
\newcommand{\bfB}{\mbox{$\bf{B}$}}
\newcommand{\bfC}{\mbox{$\bf{C}$}}
\newcommand{\bfD}{\mbox{$\bf{D}$}}
\newcommand{\bfE}{\mbox{$\bf{E}$}}
\newcommand{\bfF}{\mbox{$\bf{F}$}}
\newcommand{\bfG}{\mbox{$\bf{G}$}}
\newcommand{\bfH}{\mbox{$\bf{H}$}}
\newcommand{\bfI}{\mbox{$\bf{I}$}}
\newcommand{\bfJ}{\mbox{$\bf{J}$}}
\newcommand{\bfK}{\mbox{$\bf{K}$}}
\newcommand{\bfL}{\mbox{$\bf{L}$}}
\newcommand{\bfM}{\mbox{$\bf{M}$}}
\newcommand{\bfN}{\mbox{$\bf{N}$}}
\newcommand{\bfO}{\mbox{$\bf{O}$}}
\newcommand{\bfP}{\mbox{$\bf{P}$}}
\newcommand{\bfQ}{\mbox{$\bf{Q}$}}
\newcommand{\bfR}{\mbox{$\bf{R}$}}
\newcommand{\bfS}{\mbox{$\bf{S}$}}
\newcommand{\bfT}{\mbox{$\bf{T}$}}
\newcommand{\bfU}{\mbox{$\bf{U}$}}
\newcommand{\bfV}{\mbox{$\bf{V}$}}
\newcommand{\bfW}{\mbox{$\bf{W}$}}
\newcommand{\bfX}{\mbox{$\bf{X}$}}
\newcommand{\bfY}{\mbox{$\bf{Y}$}}
\newcommand{\bfZ}{\mbox{$\bf{Z}$}}

\DeclareMathOperator*{\argmin}{argmin} 
\DeclareMathOperator*{\argmax}{argmax} 

\usepackage[svgnames]{xcolor}
\usepackage{listings}

\lstset{language=R,
    basicstyle=\Large\tt,
    stringstyle=\color{DarkGreen},
    otherkeywords={0,1,2,3,4,5,6,7,8,9},
    morekeywords={TRUE,FALSE},
    deletekeywords={data,frame,length,as,character},
    %keywordstyle=\color{blue},
    commentstyle=\color{DarkGreen},
}

\CJKscale{0.9}
\begin{document}


\section{Measure Theory}
\ck 여기서는 듀렛책 챕터 1.1 $\sim$ 1.3 사이의 내용을 다룬다. 이 내용들은 probability spaces, distributions, random variable에 대한 내용인데 전반적으로 적분이전의 measure theory에 관한 내용이다. 개인적으로 책이 상당히 두서없이 정리되어 있다고 생각한다. 그래서 나도 두서없이 내맘대로 정리하였다. 

\ck 확률변수 $X$에 대한 정의를 생각하여 보자. 확률변수는 본질적으로 메저러블-맵핑이므로 메저러블-매핑의 정의에 대하여 알아보자. 어떠한 맵핑 $X$가 메저러블-스페이스 $(\Omega,{\cal F})$와 메저러블-스페이스 $(S,{\cal S})$를 이어주는 메저러블-맵핑이라는 의미는 1) $X$가 $\Omega$에서 $S$로 가는 함수이고 즉 $X:\Omega \rightarrow S$이고 2) $X^{-1}$가 
\begin{align*}
\forall B \in {\cal S}: X^{-1}(B) \in {\cal F} 
\end{align*} 
를 만족한다는 의미이다. 

\ck 확률변수 $X$라는 것을 정의하기 위해서는 반드시 두 메저러블-스페이스가 필요하다. 확률변수 $X$ 단독으로 정의될 수 없다. 이것은 비유하면 "남친"의 정의와 비슷하다. 남친은 혼자 될 수 있는 것이 아니다. 즉 남친은 단독으로 정의될 수 없고 "XXX의 남친"과 같은 식으로만 정의된다. 예를 들면 
\[
\mbox{\textbf{"저는 남친이에요"}}
\]
라고 말하는것은 올바른 정의가 아니며  
\[
\mbox{\textbf{"저는 XXX의 남친이에요"}}
\]
라고 말하는 것이 올바른 정의이다. 이처럼   
\[
\mbox{\textbf{"$X$는 확률변수에요"}}
\]
라고 말하는 것은 올바른 정의가 아니며 (하지만 유감스럽게도 대부분 이렇게 말하고, 그래서 확률변수가 무엇인지 헷갈려한다. 그리고 내가 매년 이러고 있다..)   
\[
\mbox{\textbf{"$X$는 두 메저러블-스페이스 $(\Omega,{\cal F})$와 $(S,{\cal S})$를 연결하는 확률변수에요"}}
\]
라고 말하는것이 올바른 정의라는 것이다. 요런 느낌의 정의를 확률론에서는 많이 가지고 있다. 가령 예를들면 시그마필드 ${\cal F}$는 홀로 정의될 수 없고 전체집합 $\Omega$가 존재해야지 정의된다. 그리고 임의의 메저러블셋 $A$은 시그마필드 $\cal F$가 있어야지 정의될 수 있다. 즉 아래와 같이 말한다.  
\[
\mbox{\textbf{"$\cal F$는 $\Omega$에 대한 시그마필드에요"}}
\]
혹은  
\[
\mbox{\textbf{"집합 $A$는 시그마필드 $\cal F$에 대해서 메저러블해요"
}}
\]
와 같은 식으로 말이다. 

\ck 확률변수는 사실 메저러블-맵핑중에서 매우 특수한 경우이다. 왜냐하면 "이미지(=image)"에 해당하는 메저러블-스페이스 $(S,{\cal S})$가 $(\mathbb{R},{\cal R})$로 고정되어있기 때문이다. 여기에서 $\cal R$은 보렐클라스이다. 그러면 사실 확률변수 $X$를 정의하는데 $\Omega$, $\cal F$, $S$, $\cal S$를 일일히 정의할 필요는 없어진다. $(S,{\cal S})=(\mathbb{R},{\cal R})$은 이미 정해졌고 $\Omega$는 ${\cal F}$를 정의하면 사실 같이 정의된 셈이나 마찬가지다($\cal F$에서 가장 큰 원소가 $\Omega$일테니깐!). 종합하면 확률변수 $X$를 정의할때는 ${\cal F}$만 정의하면 된다. 따라서   
\[
\mbox{\textbf{"$X$는 두 메저러블-스페이스 $(\Omega,{\cal F})$와 $(S,{\cal S})$를 연결하는 확률변수에요"}}
\]
라고 말하는것이 정확하지만   
\[
\mbox{\textbf{"$X$는 ${\cal F}$에서 정의된 확률변수에요"}}
\]
라고 말해도 틀린말은 아니라는 것이다. 그리고 이렇게 말하는 것을 더 좋아하는 사람들이 많다(간단하니깐). 그리고 이것을 기호로는
\[
X \in {\cal F}
\]
라고 쓴다. 

\ck 아마 나는 이 포스팅을 읽을때마다 보렐클라스가 무엇인지 다시 헷갈리기 시작할것이다(나 자신에 대한 끝없는 불신..). 그래서 보렐클라스에 대해서 다시 정의하고 넘어가겠다. 보렐클라스 $\cal R$이란 $\mathbb{R}$의 모든 오픈셋을 포함하는 시그마필드라는 것이다. 좀 더 엄밀하게 써보자. 집합 $O$를 $\mathbb{R}$에 속하는 임의의 오픈셋이라고 하자. 즉 
\begin{align*}
O \subset \mathbb{R} ~~~ and ~~ O ~~ is ~~ open ~~ set
\end{align*}
이라고 하자. 이러한 집합 $O$들을 모아놓은 클라스를 $\cal O$를 정의하자. 즉 
\begin{align*}
{\cal O}=\{O: O \subset \mathbb{R}, ~~~ O ~~ is ~~ open ~~ set \}
\end{align*}
이다. $\cal R$은 $\cal O$를 포함하는 가장 작은 시그마필드이다. 즉 (1) ${\cal O} \subset {\cal R}$이고 (2) "${\cal R}$ is $\sigma$-field." 이다. 이것을 기호로는 아래와 같이 쓴다. 
\begin{align*}
{\cal R}=\sigma({\cal O})
\end{align*}
그리고 ${\cal R}$을 $\cal O$에 의해서 제너레이트된 시그마필드라고도하며 $\cal O$가 $\cal R$을 생성했다고 말하기도 한다. 

\ck 보렐클라스는 우리가 상상할 수 있는 대부분의 "subset of $\mathbb{R}$"을 포함한다. 가령 예를들면 보렐클라스는 점집합, 인터벌, 레이와 같은 집합들을 포함하는데 이는 이러한 집합들이 $(a,b)$의 카운터블 유니온꼴로 표현될 수 있다는 것을 알면 쉽게 이해할 수 있다. 이러한 집합을 $\cal R$-메저러블한 집합이라고 표현한다. 간단히 줄여서 보렐셋이라고 표현하기도 한다. 하지만 "subset of $\mathbb{R}$"임에도 불구하고 가끔 가다가 보렐클라스의 원소가 아닌 이상한 집합이 있을 수도 있다. 이런 집합을 보렐클라스의 원소가 아닌 집합 혹은 $\cal R$-메저러블하지 않은 집합 혹은 보렐셋이 아닌 집합이라고 한다. 대표적으로 비탈리집합이 있다. 

\ck 보렐셋 즉 $\cal R$-메저러블한 집합은 $\mathbb{R}$에서 \textbf{"길이를 잴 수 있는 집합"}이라고 이해해도 괜찮다. 가령 예를 들면 $[0,1]$의 길이는 1이고 $\emptyset$의 길이는 0이다. 또한 $\{0\}$와 같은 집합의 길이는 0, 유리수들의 집합의 길이는 0, 그리고 $[0,1]$사이에 포함된 무리수들의 집합을 길이로 재면 $1$과 같은식으로 정의할 수 있다. 따라서 위에서 언급한 집합들은 모두 잴 수 있는 집합이며, $\cal R$-메저러블한 집합이다. 

\ck 참고로 위와 같이 길이를 재는 함수를 \textbf{르벡메저}라고 한다. 르벡메저는 $\cal R$에 속한 임의의 집합에 대하여서도 이러식으로 \textbf{모순없이} 길이를 정의할 수 있다. 여기에서 모순없이 길이를 잴 수 있다는 말이 의미하는 것은 (1) 공집합의 길이는 0이며 (2) $\cal R$에 속하는 어떠한 집합의 길이도 양수이어야 하며 3) $\cal F$에 속하는 두 집합이 서로소라면(즉 $[0,1]$, $[3,4]$와 같은 집합) 두 집합의 합친집합의 길이는 각각의 길이의 합과 같아야 한다는 것이다(즉 $[0,1]\cup[3,4]$의 길이는 $[0,1]$의 길이와 $[3,4]$의 길이의 합과 같아야한다는것임). 어떠한 클라스 $\cal F$에서 이러한 위와 같은 조건을 만족하는 함수 $\mu$가 있다고 하면 이때 $\mu$는 $\cal F$의 모든 원소들의 크기(혹은 길이)를 \textbf{모순없이} 정의할 수 있다. 이러한 함수 $\mu :{\cal F} \rightarrow [0,\infty]$를 $\cal F$에서의 메저라고 한다. 참고로 \textbf{르벡메져} $\lambda$는 아래와 같이 정의되는 함수이다. 
\begin{align*}
\lambda((a,b])=b-a
\end{align*}
이러한 함수 $\lambda$는 보렐클래스 $\cal R$에 있는 모든집합에 대하여 \textbf{모순없이} 길이를 정의할 수 있다. 따라서 $\lambda$는 $\cal R$에 대한 메져이다. 

\ck 다시 $X$로 관심을 돌려보자. $X$는 기본적으로 $\Omega$와 $\mathbb{R}$을 연결하는 맵핑이다. 이것이 $(\Omega,{\cal F})$와 $(\mathbb{R},{\cal R})$을 연결하는 맵핑, 즉 메저러블 맵핑이 되려면 어떻게 되어야 할까? 해답은 매우 간단하다. \textbf{$\Omega$의 원소들을 근원사건으로 해석하여 맵핑하지말고 $\cal F$의 (공집합을 제외한) 가장 작은 원소들을 근원사건으로 해석하여 맵핑시키면 된다.} 이제 이게 무슨말인지 찬찬히 살펴보자. 예를들어 
\[
\Omega=\{1,2,3,4,5,6\}
\]
이라고 하자. 즉 주사위를 던져서 나오는 눈들의 집합이 $\Omega$이다. $\Omega$의 원소를 기준으로 이해한 근원사건은 다음과 같다.
\begin{itemize}
	\item 주사위를 던져서 눈이 1이 나올 경우
	\item $\dots$
	\item 주사위를 던져서 눈이 6이 나올 경우
\end{itemize}
이제 $\Omega$에 대한 시그마필드를 아래와 같이 정의하자. 
\begin{align*}
{\cal F}=\{\emptyset, \{1,3,5\}, \{2,4,6\},\Omega \}.
\end{align*}
즉 $\cal F$의 원소는 (1) 공집합 (2) 전체집합 그리고 (3) 주사위를 던져서 짝수가 나오는 경우를 모은 집합 (4) 주사위를 던져서 홀수가 나오는 경우를 모은 집합이다. 이 경우 $\cal F$의 (공집합을 제외한) 가장 작은 원소를 기준으로 이해한 근원사건은 다음과 같다.  
\begin{itemize}
	\item 주사위를 던져서 짝수가 나올 경우
	\item 주사위를 던져서 홀수가 나올 경우
\end{itemize}
$X$가 단지 $\Omega$에서 $\mathbb{R}$의 맵핑이 아니라 $(\Omega,{\cal F})$에서 $(\mathbb{R},{\cal R})$로 메저러블맵핑이 되려면 \textbf{$\cal F$의 (공집합을 제외한) 가장 작은 원소를 기준으로 맵핑을 해야한다.} 즉 
\begin{align*}
X(\{1\})=1 
\end{align*}
\[
\dots
\]
\begin{align*}
X(\{6\})=6
\end{align*}
와 같이 맵핑을 하면 안되고 
\begin{align*}
X(\{1\})=X(\{3\})=X(\{5\})=1 
\end{align*}
\begin{align*}
X(\{2\})=X(\{4\})=X(\{6\})=0
\end{align*}
와 같은 식으로 맵핑을 해야한다는 것이다. 참고로 전자의 맵핑은 
\[
\mbox{\textbf{"$X$: 주사위를 던져서 나오는 눈의 수"}}
\]와 같은 식으로 확률변수를 구성한 것이고 후자의 경우는 
\[
\mbox{\textbf{"$X$: 주사위를 던져 홀수면 1 짝수면 0"}}
\]
과 같은 방식으로 확률변수를 구성한 것이다. 전자의 근원사건은 주사위를 던져서 나온 눈의 수이며 후자의 근원사건은 주사위를 던져서 짝수가 나왔는지 홀수가 나왔는지다. 참고로 후자의 경우처럼 $X$를 맵핑해야 $X$가 $\cal F$에서 정의된 랜덤변수 즉 $X \in {\cal F}$라고 할 수 있는 것이다. 

\ck \textbf{$X \in {\cal F}$가 되도록 $X$를 정의하기 위해서는} 위처럼 ${\cal F}$가 근원사건을 이해하는 방식으로 맵핑 $X$를 정의해도 되지만 \textbf{${\cal F}$보다 작은 어떤 시그마필드 ${\cal F}^* $의 가장 작은 원소를 기준으로 맵핑 $X$를 정의해도 된다.} 예를들면 위의 예제처럼 
\begin{align*}
{\cal F}=\{\emptyset, \{1,3,5\}, \{2,4,6\},\Omega \}.
\end{align*}
라고 하고 우리는 $X \in {\cal F}$가 되도록 맵핑 $X$를 잘 정의하고 싶다고 하자. $X$를 위의 예제처럼 ${\cal F}$의 최소원소를 기준으로 맵핑하 아래와 같다. 
\begin{align*}
X(\{1\})=X(\{3\})=X(\{5\})=1 
\end{align*}
\begin{align*}
X(\{2\})=X(\{4\})=X(\{6\})=0
\end{align*}
당연히 $X \in {\cal F}$은 성립한다. 그렇다면 ${\cal F}$보다 작은 집합 ${\cal F}^* $, 예를들면 
\[
{\cal F}^* = \{\emptyset, \Omega\}
\]
와 같은 시그마필드의 최소원소를 기준으로 $X$를 맵핑해도 여전히 $X\in {\cal F}$가 성립할까? 그러하다. 예컨데 아래와 같은식으로 $X$를 맵핑해도된다. 
\begin{align*}
X(\{1\})=X(\{2\})=X(\{3\})=X(\{4\})=X(\{5\})=X(\{6\})=1.
\end{align*}
이렇게 정의하여도 $X \in {\cal F}$가 성립한다. 단지 이러한 경우 ${\cal F}$는 $X$를 정의하기 위해서 필요한 최소한의(=가장작은) 시그마필드는 아니게 된다. 이 경우 $X$를 정의하는데 필요한 최소한의 시그마필드는 ${\cal F}^* $가 된다. 이처럼 맵핑 $X$를 ${\cal F}$ 메저러블하도록 만드는데 필요한 최소한의 시그마필드를 기호로 $\sigma(X)$라고 한다. 그리고 이 예제에서는 $\sigma(X)={\cal F}^* $가 된다. 

\ck 이제 $\cal F$에서 정의된 어떠한 확률변수 $X$가 $\cal F$의 모든 사건들을 \textbf{잘} 연결하는 어떠한 맵핑이라는건 알겠다. 그런데 확률변수 $X$가 어떤 \textbf{랜덤}한 출력을 주는 함수라는 느낌은 없다. 왜냐하면 말그대로 확률변수 $X$는 두 메저러블 스페이스 $(\Omega, {\cal F})$, $(\mathbb{R},{\cal R})$을 잘 연결하는 어떠한 맵핑일 뿐이기 때문이다. 즉 $X$는 단순히 함수(혹은 맵핑)이기 때문에 $\omega \in \Omega$가 고정되면 $X(\omega)$의 값도 고정된다. 따라서 $X$가 어떤 \textbf{랜덤}한 출력을 가지도록 하기 위해서는 $\omega$를 랜덤하게 선택하는 수밖에 없다. 이렇게 $\omega$를 랜덤하게 선택할 수 있게 만들어주는 장치가 바로 확률척도 $P:{\cal F} \rightarrow \mathbb{R}$이다. $P(\{\omega\})$는 $\Omega$에서 $\{\omega\}$가 선택될 확률을 의미한다. 따라서 $P$는 $\omega$를 \textbf{랜덤}하게 선택할수 있게 해주고 그 결과 $X(\omega)$의 출력 역시 \textbf{랜덤}하게 나올 수 있도록 해준다. 따라서 우리가 일반적으로 생각하는 확률변수 $X$를 정의하기 위해서는 $(\Omega, {\cal F}), ~ (\mathbb{R},{\cal R})$과 더불어서 $P$가 추가적으로 필요하다. 즉 확률변수 $X$를 정의하기 위해서는 $(\Omega,{\cal F},P), ~ (\mathbb{R},{\cal R})$이 필요하다. 여기에서 $(\Omega, {\cal F}, P)$를 묶어서 확률공간이라고 한다. 

\ck 엄밀하게 말하면 $X$를 정의하기 위해서는 $(\Omega, {\cal F},P), ~ (\mathbb{R},{\cal R})$가 모두 필요하지만 앞에서 언급하였듯이 ${\cal F}$를 알면 $\Omega$를 아는 셈이고 (${\cal F}$에서 젤 큰 집합이 $\Omega$임) $(\mathbb{R},{\cal R})$는 이미 정해진 것이므로 $X$를 정의하는데 최소한으로 필요한 정보는 ${\cal F}$와 $P$이다. 그런데 이 사실은 $X \in {\cal F}$라는 기호를 이상하게 느껴지게 만들 수 있다. 즉 "$X$를 \textbf{well-define} 하는데 ${\cal F}$만 필요하다고 하면 된다고 했는데 사실 그게 아니고 $P$도 필요한것 아니야?" 라고 생각할 수 있다. 하지만 $P$는 사실 $X$가 가지는 \textbf{랜덤}성을 주기 위한 장치이고 \textbf{따라서 $P$를 잘 못 정의한다고 하여서 $X$가 랜덤변수가 아니게 되는 경우는 없다}($P$가 probability measure가 되도록만 정의하면 됨)는 사실을 유의하면 $X$를 \textbf{well-define}하기 위해서는 $P$가 필요하지 않음을 알 수 있다. 즉 아래의 기호는 여전히 유용하다. 
\begin{align*}
X \in {\cal F}
\end{align*}

\ck 그럼 $P$가 가지는 역할은 무엇일까? $P$는 $X$는 가지는 분포를 결정하여 준다. 따라서 $P$는 맵핑 $X$가 확률변수인지 아닌지를 결정하지는 않지만 (이것은 ${\cal F}$가 결정함) $X$가 \textbf{어떠한} 확률변수인지는 결정한다. 즉 $P$가 정의되면 부수적으로 $X$가 가지는 여러가지 성질들을 추가적으로 \textbf{assume} 할 수 있다. 예를들어 $P$는 확률변수의 모멘트가 유한한지 그렇지 않은지를 결정할 수 있으며 확률변수들이 독립인지 아닌지도 결정할 수 있다. (예컨데 $P:=P_1 \times P_2$를 확률벡터 $(X_1,X_2)$의 확률측도라고 하자. 여기에서 $P_1, P_2$는 각각 $X_1, X_2$의 probability measure이다. 이때 $P$를 알고있다면 두 확률변수 $X_1$, $X_2$ 가 독립인지 독립이 아닌지도 알 수 있다.)

\ck 확률척도 $P$는 $X$의 분포에 대한 정보를 담고 있지만 $P$의 정의역은 ${\cal F}$이다. $P$의 정의역이 보렐셋 ${\cal R}$이 아니기 때문에 종종 $P$를 쓰기 불편할 때가 있다. 그래서 $P$와 동등한 역할을 하는 또 다른 함수 $\mu^{\bigstar}: {\cal R} \rightarrow [0,1]$를 아래와 같이 만든다. 
\begin{align*}
\mu^{\bigstar} := P \circ X^{-1}. 
\end{align*}
이때 $\tilde \mu$를 확률변수 $X$의 \textbf{distribution}이라고 정의한다. 이렇게 정의하면 임의의 집합 $B \in {\cal R}$에 대하여 아래식이 성립한다. 
\begin{align*}
\mu^{\bigstar}(B)=P(\{\omega: X(\omega) \in B\})=P(A)
\end{align*}
여기에서 $A:=X^{-1}(B):=\{\omega: X(\omega) \in B\}$로 정의한다. 참고로 이때 $\mu^{\bigstar}$는 확률측도가 된다(증명은 알아서 하든가 아니면 그냥 믿든가). 따라서 $(\mathbb{R},{\cal R},\mu^{\bigstar})$는 확률공간이 된다. 여기에서 $\mu^{\bigstar}$가 $X$에 의해서 정의되므로 확률공간 $(\mathbb{R},{\cal R},\mu^{\bigstar})$ 역시 $X$에 의해서 정의되는데 이러한 이유로 \textbf{확률공간 $(\mathbb{R},{\cal R},\mu^{\bigstar})$를 $X$에 의해서 유도된 확률공간이라고 표현하기도 한다.}

\ck 참고로 보통 교재에서는 $\mu^{\bigstar}$ 대신에 간략하게 $\mu$를 쓴다. 나는 일반적인 메져 $\mu$ 와 확률변수 $X \in {\cal F}$ 의 distribution 으로서의 (probability) measure 를 구분하기 위해서 $\bigstar$를 붙였다. 

\ck 확률변수 $X$에 대한 \textbf{distribution} $\mu^{\bigstar}$까지 잘 정의하였다면 확률변수 $X$에 대한 \textbf{distribution function}을 정의할 수 있다. 확률변수 $X$의 \textbf{distribution function} $F:\mathbb{R} \rightarrow [0,1]$는 아래와 같이 정의한다. 
\begin{align*}
F(x)=\mu^{\bigstar}((-\infty,x])=P(\{\omega: X(\omega) \leq x\})
\end{align*}
$F(x)$는 $X$의 \textbf{cdf}라고 표현하기도 한다. 참고로 $F(x)$는 (1) $F(-\infty)=0, F(\infty)=1$을 만족하고 (2) 비감소이며 (3) 오른쪽 연속인 함수가 된다. 그리고 임의의 함수 $F(x)$가 위의 3가지 조건을 만족하면 $F(x)$는 어떠한 확률변수 $X$의 \textbf{distribution function}이 된다.

\ck 여기에서 어떠한 확률변수 $X$인지 구체적으로 알아보도록 하자. 결론적으로 
\[
X(\omega):= \sup \left\{ y : F(y)<\omega \right\}
\]와 같이 하면 이 확률변수는 $F(x)$를 \textbf{distribution function}으로 가지는 하나의 확률변수가 된다. 

\ck 만약에 $F(x)$가 $x$에 대하여 미분가능하다면 
\begin{align*}
f(x)=\frac{d}{dx}F(x) 
\end{align*}
를 만족하는 $f(x)$를 정의할수 있는데 이때 $f(x)$를 $X$의 \textbf{probability density function}이라고 한다. 그럼 언제 $f(x)$가 존재할까? \textbf{라돈-니코딤} 정리는 $X$ 의 \textbf{distribution}, $\tilde \mu:P \circ X^{-1}$ 가 르벡메져 $\lambda$ 에 대하여 \textbf{absolutely continuous}하다면 $X$ 의 pdf가 존재함을 시사한다. 

\ck 좀 더 자세히 설명해보자. 내가 알고있기로는 결국 모든 $x\in\mathbb{R}$에 대하여 
\begin{align*}
\int_{-\infty}^{x} f(\tau) d\tau = F(x) 
\end{align*}
가 만족하는 $f(x)$가 존재함을 보이면 된다. 참고로 위와 같이 고등학교에서 배운것같은 기호로 정의된 적분은 \textbf{리만적분}이라고 보아도 무방하다. 참고로 
\begin{align*}
\lambda\Big(\{ x: f(x) \mbox{ is discontinuous on } x\} \Big)=0
\end{align*}
아래가 성립하면 
$f(x)$는 리만적분가능에서 \textbf{르벡적분가능}으로 바뀌며 따라서 
\begin{align*}
\int_{-\infty}^{x} f(\tau) d\tau=\int_{(-\infty,x]} fd\lambda
\end{align*}
이 된다(김김계 해석개론, p.313, 정리 10.3.4). 여기에서 $\lambda$는 르벡메져이다. 따라서 모든 $x \in \mathbb{R}$ 에 대하여 $\int_{-\infty}^{x} f(\tau) d\tau = F(x)$ 가 성립하는 $f$ 가 존재함을 보이기 위해서는 모든 $B \in {\cal R}$에 대하여 아래식이 성립하게 하는 함수 $f$ 가 존재함을 보이는 것과 같다. 
\begin{align*}
\int_B f d\lambda = \mu^{\bigstar} (B)
\end{align*}
그런데 $\mu^{\bigstar} \ll \lambda$ 이기만 하면 위의 식을 만족하는 메져 $f$가 반드시 존재함이 \textbf{라돈-니코딤} 정리에 의하여 알려져 있다. 여기에서 $\mu^{\bigstar} \ll \lambda$는 메져 $\mu^{\bigstar}$가 메져 $\lambda$에 대하여 \textbf{absolutely continuous} 하다는 의미이다(제발 매우작다라고 해석하지 말자). 참고로 원래 \textbf{라돈-니코딤}정리를 쓰려면 $\mu^{\bigstar}$, $\lambda$가 $\sigma$-finite 메져라는 조건이 추가적으로 필요한데 이 경우에는 $\mu^{\bigstar}$는 확률측도이고 $\lambda$는 르벡측도이므로 이 조건이 그냥 만족된다. 따라서 증명이 된다. 

\ck 이제 $B:=(-\infty,x] \in {\cal R}$ 와 $A:=X^{-1}(B) \in {\cal F}$ 에 대하여 아래와 같은 기묘한 표현들을 파악하여 보자. 
\begin{align*}
& \int_A dP = P(A) = P(X \in B) =  \int_{X^{-1}(B)} dP = P(X^{-1}(B)) \\
& = \mu^{\bigstar}(B) = \int_B d\mu^{\bigstar} = \int_B \mu^{\bigstar}(dx) = P(X \leq x) = \int_{-\infty}^{x} f(\tau)d\tau \\ 
& = \int_{B} fd\lambda=\int_{B} f(x)\lambda(dx)= \int_{-\infty}^{x}dF(\tau) =F(x)-F(-\infty)=F(x)
\end{align*}
참고로 여기에서 $B$를 일반적인 보렐셋대신 ray를 사용하였는데, 이렇게 쓸 수 있는 이유는 임의의 보렐셋이 $(-\infty,x]$ 들의 \textbf{countable union} 으로 쉽게 확장가능하기때문이다. (김김계 해석개론, p295, 명제 10.1.1) 예를들어서 $(1,3]=(-\infty,3] - (-\infty,1]$와 같은 식으로 말이다. 아무튼 이걸 활용하면 임의의 보렐셋에 대한 적분도 표현가능하지만 그 표현법이 지저분하므로 $B$ 를 ray로 단순화 시켰다. 참고로 아래와 같은 표현들도 자주 사용된다. 
\begin{align*}
& \int_A X dP=\int_A X(\omega)P(d \omega) 
\int_{-\infty}^{x}\tau f(\tau)d\tau \\
& = \int_B x f(x) \lambda(dx) = \int_{-\infty}^{x} \tau dF(\tau) = \int_B x d{\mu}^{\bigstar} = \int_B x \mu^{\bigstar}(dx)
\end{align*}
참고로 위에서 $\int_{-\infty}^{x}\tau f(\tau)d\tau=\int_{-\infty}^{x} \tau dF(\tau)$ 는 스틸체스 적분의 성질 (김김계 해석개론, p.151, 정리 5.5.3)에 의해서 성립한다. 

\section{Integration}
\ck 여기에서는 듀렛책 챕터 1.4 $\sim$ 1.7의 내용을 다룬다. 

\ck $f:\Omega \rightarrow \mathbb{R}$가 두 가측공간 $(\Omega,{\cal F})$와 $(\mathbb{R},{\cal R})$를 이어주는 매저러블-맵핑이라고 하자. 그리고 $\mu:{\cal F} \rightarrow \mathbb{R}$은 ${\cal F}$에서의 메저라고 하자. 여기에서 특별히 $\mu$는 $\sigma$-finite measure라고 정의한다. 당분간은 $f=X$ 이고 $\mu=P$ 라고 생각해도 무방하다. (좀 더 발전하면 $f=f(X)$라고 두기도 한다. 어차피 $f(X)$ 즉 function of $X$는 또 다른 확률변수로 볼 수 있으므로 같은 논의이다.) 이 챕터에서 우리의 관심은 (1) 메저러블-맵핑 $f$를 메저 $\mu$로 적분한것 즉 
\begin{align*}
\int f d \mu
\end{align*}
를 잘 정의하고 (2) 적분관련 성질들을 자유자재로 계산할 수 있는 적당한 조건을 알아보는 것이다. 여기에서 적분관련 성질들은 예를들어 
\begin{align*}
\int af d\mu = a \int f d \mu 
\end{align*} 
\begin{align*}
\int f+g d\mu = \int f d \mu + \int g d \mu 
\end{align*} 
와 같은 것들을 의미한다. 

\ck  $\int f d \mu$를 정의하기 위해 필요한 기본가정을 살펴보자. 여기에서 $\mu:=P$ 임을 유의하면서 읽자. (절대로 $\mu=\mu^{\bigstar}$가 아님)

\one $f:(\Omega,{\cal F}) \rightarrow (\mathbb{R},{\cal R})$ 이 어야 한다. 즉 $f$ 가 메저러블 맵핑 이어야 한다. 왜냐하면 적분 $\int f d \mu$ 를 수행하기 위해서는 임의의 $B \in {\cal R}$ 에 대한 $f$의 inverse image, 
\begin{align*}
A:=\{\omega: f \in B \}
\end{align*}
를 구하고 그 $A$에 대한 메저 $\mu(A)$를 계산해야 하는데, 이 $\mu(A)$가 정의되기 위해서는 $A \in {\cal F}$이어야 하기 때문이다. 

\two $\mu$가 $\sigma$-finite measure 이어야 한다. 왜냐하면 이 조건이 있어야 임의의 $A \in {\cal F}$에 대하여서도 $\mu(A)<\infty$가 성립하게 되어서 $d \mu$부분을 상당히 안정적으로 정의할 수 있다. 

\three $f$와 $\mu$가 같은 시그마필드 $\cal F$를 공유하고 있어야 한다. 

\four 마지막으로 $\mu$와 $f$는 항상 치역 $\mathbb{R}$을 가져야 한다. $\mu$는 당연히 정의상 치역을 $\mathbb{R}$을 가질수 밖에 없으므로 $f$의 치역이 항상 $\mathbb{R}$이어야 한다는 조건으로 이해할 수 있다. 즉 $f$는 치역으로 $\mathbb{R}^n$도 가질 수 없다. 따라서 랜덤벡터와 같이 $f$의 치역이 $\mathbb{R}^n$인 경우는 바로 적분안된다. ($\mu$의 치역은 $\mathbb{R}$가 되어서 임의의 $A \in {\cal F}$에 대하여 $f(A)\mu(A)$를 정의할 수 없다.) 

\ck 왜 적분을 measure theory를 이용하여 정의할까? 고등학교때 정의하던대로 하면 안되나? 다 이유가 있어서 이렇게 정의하는 것이다. measure theory 를 이용하여 적분을 정의하면 고등학교때 배운 논리로 정의하기 애매하 적분들을 매우 깔끔하게 정의할 수 있다는 장점이 있다. 가령 예를들면 모든 유리수에서 $1$의 값을 가지고 나머지는 $0$을 가지는 함수 $f$를 생각하여 보자. 즉 $f$는 아래와 같다. 
\begin{align*}
f(x)=\begin{cases} 1 & x \in \mathbb{Q} \\ 0 & x \notin \mathbb{Q} \end{cases}
\end{align*}
이 함수 $f$에 대한 적분은 고등학교때 배운 구분구적법 혹은 리만적분과 같은 방식으로는 정의할 수 없다(얼핏 생각하면 리만적분으로는 가능할것 같은데 불가능하다고 한다 $f$를 리만적분하면 0과 1사이의 임의의 값이 랜덤으로 정의된다고 한다). 하지만 measure theory를 이용하면 이 적분값은 0으로 깔끔하게 정의된다. 즉 
\begin{align*}
\int f d\lambda=0
\end{align*}
으로 깔끔하게 정의된다. 여기에서 $\lambda$는 르벡메져이며 이러한 적분을 \textbf{르벡적분}이라고 한다. 기본적으로 구분구적법이나 리만적분은 $f$가 연속이거나 부분적으로 연속이어야 할 것 같은 느낌인데 measure theory를 이용한 르벡적분은 $f$가 매저러블 맵핑이기만 하면 되므로 좀 더 적분을 정의할 수 있는 함수의 선택폭이 넓다. 일단 ${\cal R}$자체가 거의 대부분의 "subset of $\mathbb{R}$"을 커버하고 있기 때문에 ${\cal R}$-메저러블하지 않는 함수 $f:\mathbb{R} \rightarrow \mathbb{R}$는 별로없다고 보는 편이 좋다. 즉 르벡적분 불가능한 함수 $f:\mathbb{R} \rightarrow \mathbb{R}$는 별로없다고 보는것이 맞다.

\ck 이제 메저러블-맵핑 $f$의 적분을 \textbf{모순없이} 정의하는 방법을 살펴보자. 적분은 기본적으로 넓이를 구하는 개념이므로 $f:\Omega \rightarrow \mathbb{R}$가 \textbf{simple function}일때  $\mu:{\cal F} \rightarrow \mathbb{R}$에 대한 적분은 사각형넓이의 유한합으로 매우 명확히 정의할 수 있다. 이것에 대한 내용이 듀렛책에 설명되어 있지만 당연한 소리라서 생략하겠다. 

\ck 여기까지는 당연한거라서 우리의 관심은 \textbf{"$f$가 simple function이 아닐 경우에도 $\mu$에 대한 적분을 모순없이 잘 정의할 수 있을까?"}가 된다. 결론적으로 
\textbf{\textcolor{red}{아래의 3가지 경우}}에서는 적분값 $\int f d \mu$가 (마치 simple function 인것마냥) 모순없이 잘 정의되며 $\int af d\mu = a \int f d \mu$, $\int f+g d\mu = \int f d \mu + \int g d \mu$ 따위의 성질들도 모순없이 잘 성립한다. 

\one  $f$가 $\mu$ 에 대하여 \emph{\textbf{거의(=almost) bounded function}} 인 경우 

\two  $f$가 $\mu$ 에 대하여 \emph{\textbf{거의(=almost) non-negative function}}인 경우 

\three $f$가 $\mu$ 에 대하여 \emph{\textbf{integrable}}인 경우, 즉 $\int |f| d\mu < \infty$ 인 경우

\ck 먼저 (1) $f$가 bounded function 인 경우를 살펴보자. $f$를 두 simple function $\phi$, $\psi$ 사이에 끼워넣고, 즉 $\phi \leq f \leq \psi$ 와 같이 만든 다음 $\int f d\mu $를 아래와 같이 정의하면 $f$가 simple function 일때 마냥 $\mu$에 대한 적분값을 잘 정의할 수 있다. 
\begin{align*}
\sup_{\phi \leq f} \int \phi d\mu = \int f d\mu = \inf_{\psi \geq f} \int \psi d\mu. 
\end{align*}
참고로 위의 정의가 말이 되려면 즉 모순이 되지 않으려면 
\[
\sup_{\phi \leq f} \int \phi d\mu = \inf_{\psi \geq f} \int \psi d\mu
\]
가 성립해야 하는데 이것이 성립하는 것은 듀렛책에 증명이 되어있다. 

\ck 위의 결과를 이용하면 (2) $f$가 non-negative function인 경우에도 $\mu$에 대한 적분을 쉽게 정의할 수 있다. 먼저 $h$를 $0\leq h \leq f$를 만족하는 bounded function이라고 하자. $\int f d\mu$는 아래와 같이 $\int h d \mu$의 sup으로 정의할 수 있다. 
\begin{align*}
\int f d\mu = \sup_{0\leq h \leq f} \int h d \mu
\end{align*}

\ck 이제 (3)의 경우를 살펴보자. 일반적인 $f$는 아래와 같이 표현가능하다. 
\begin{align*}
f=f^+ -f^-
\end{align*}
따라서 $\int f d\mu$는 아래와 같이 정의할 수 있다. 
\begin{align*}
\int f d\mu = \int f^+ d\mu - \int f^- d\mu
\end{align*}
단지 위의 식이 모순없이 정의되려면 $\int f^+ d\mu$와 $\int f^- d\mu$이 모두 무한대이면 안되는데 이런 경우는 $\int |f| d\mu < \infty$라는 조건에 의해서 방지된다. 

\ck 참고로 $\int |f| d\mu < \infty$를 만족하는 $f$를 우리는 \textcolor{blue}{\textbf{\emph{integrable하다}}}고 하는데 이 표현이 좀 사람 헷갈리게 만든다. 즉 
\begin{align*}
& \mbox{$f$ is \emph{integrable} wrt to $\mu$} \\ 
& \Longleftrightarrow \mbox{$\int fd\mu$ has finite value}
\end{align*}
이다. 그래서 나는 이 표현대신에 \textcolor{blue}{\textbf{\emph{유한적분값을 가진다}}}라고 표현하겠다.

\note 즉 교재에서 인테그러블 하다는 것은 말그대로 유한 적분값을 가진다는 말이지 적분을 모순없이 정의할 수 있다는 의미는 아니다. 아래를 참고하라.
\begin{itemize}
	\item 르벡적분이 불가능한 경우 (= 적분이 well define 되지 않음).
	\item 르벡적분이 가능한 경우 (= 적분이 well define 됨).
	\begin{enumerate}[(i)]
		\item $f$가 $\mu$에 대하여 integrable한 경우. 즉 $\int |f|d\mu<\infty$인 경우. 
		\item $f$가 non-negative, a.e., wrt $\mu$인 경우. (\textcolor{red}{이 경우 $\int |f|d\mu=\infty$ 가능})
		\item $f$가 bounded, a.e., wrt $\mu$인 경우. 
	\end{enumerate}
\end{itemize}

\section{Independence}
\parablue{Definition} 독립의 정의는 아래와 같다. 
\begin{align*}
&\bullet ~ \mbox{Two events $A$ and $B$ are indep}~ \overset{def}{\Longleftrightarrow} ~ P(A\cap B)=P(A)P(B).\\
&\bullet ~ \mbox{Two random variables $X$ and $Y$ are indep} \\ 
& \quad \overset{def}{\Longleftrightarrow} \mbox{for all $C,D \in {\cal R}$}: P(X\in C, Y \in D)=P(X \in C)P(Y \in D).\\
&\bullet ~ \mbox{Two $\sigma$-fields ${\cal F}$ and ${\cal G}$ are indep} \\
& \quad \overset{def}{\Longleftrightarrow} \mbox{for all $A \in {\cal F}$ and $B \in {\cal G}$ the events $A$ and $B$ are indep.}
\end{align*}
아래예제에서 확인할 수 있듯이 2번째 정의는 3번째 정의의 스페셜케이스이다. \footnote{As the next exercise shows, the second definition is a special case of the third.}

\para{Ex 2.1.1.} (i) $X$ and $Y$ 가 독립이면 $\sigma(X)$ and $\sigma(Y)$ 도 독립임을 보여라. (ii) 역으로 ${\cal F}$ and ${\cal G}$ 가 독립이고 $X\in {\cal F}$ and $Y\in{\cal G}$이면 $X$ and $Y$가 독립임을 보여라. 

\para{Ex 2.1.2.} (i) $A$ and $B$ 가 독립이면 $A^c$ and $B$ 도 독립이고 $A^c$ and $B^c$ 도 독립이고 $A^c$ and $B^c$ 도 독립임을 보여라. (ii) 아래를 보여라. 
\[
\mbox{$A$ and $B$ are indep $\Longleftrightarrow$ $1_A$ and $1_B$ are indep.}
\]

\ck 확률변수의 독립

\ck 시그마필드의 독립 

\subsection{Sufficient conditions for Independence}

\para{Ex 2.1.18.} 코인을 무한히 던진다고 가정하자. $\Omega=(0,1)$이고 ${\cal F}$를 $(0,1)$의 all open interval로 생성한 시그마필드라고 하자. (즉 보렐셋츠.) $P$를 르벡메져라고 하자. 확률변수 $Y_n(\omega)$를 아래와 같이 정의하자. 
\[
Y_n(\omega)=\begin{cases}
1  & [2^n\omega] \mbox{ is odd.} \\
0  & [2^n\omega] \mbox{ is even.} \\
\end{cases}
\]
그러면 $Y_1,Y_2,\dots$는 서로 독립이고 $P(Y_k=0)=P(Y_k=1)=1/2$이다. 

\section{WLLN}

\ck WLLN 과 SLLN 은 근본적으로 어떠한 확률변수의 합 $S_n$을 적당한 오더 $b_n$으로 나누었을때 그 값이 하나의 값으로 $p$-수렴하는지를 따지는것이다. 즉 
\begin{align*}
S_n / b_n \overset{p}{\to} ??
\end{align*}
혹은 
\begin{align*}
S_n / b_n \overset{as}{\to} ??
\end{align*}
에 대하여 관심이 있다. 가장 이상적으로는 ?? 의 값이 $E(S_n/b_n)$ 이 되는 것인데 이러한 경우를 LLN이 성립한다고 한다. 구체적으로는 $p$-수렴이 성립하는 경우를 WLLN 이라고 하고 $as$-수렴이 성립하는 경우를 SLLN 이라고 한다. 

\ck 주의할점은 우리가 항상 $S_n=X_1+\dots+X_n$ 이며 $b_n=n$ 인 형태만 관심있는것은 아니라는 것이다. 가령 아래와 같은 것들의 수렴에 관심이 있을 수도 있다. 
\begin{align*}
X_1, \frac{X_1+2 X_2+X_3}{1+2+1}, \frac{X_1+2X_2+3X_3+2X_4+X_5}{1+2+3+2+1}, \dots 
\end{align*}
즉 일명 가중평균에 대한 관심이 있을수 있다. 특히 위와 같이 커널과 같은 방식으로 가중치를 줄 경우 수렴성에 대하여 관심을 많이 가진다. 이러한 가중평균을 잘 표현하는 방법중 하나는 바로 삼각수열 $X_{n,1},\dots,X_{n,n}$ 을 활용하는 경우이다. 여기에서 \textcolor{red}{$X_{n,1}$ 은 $\textbf{weight} \times X_1$로 해석할 수 있다.} 따라서 통상적으로 $S_n$은 아래와 같이 정의하는 것이 맞다. 
\begin{align*}
S_n=X_{n,1}+X_{n,2}+\dots+X_{n,n}
\end{align*}

\ck 앞에서 말한것처럼 WLLN 은 아래에 관심이 있다. 
\begin{align*}
S_n / b_n \overset{p}{\to} ??
\end{align*}
여기에서 ?? 의 값은 (case1) 하나의 실수값으로 수렴하지 않을 경우 (case2) 하나의 실수값으로 수렴은 하지만 그 실수값이 $E(S_n/b_n)$은 아닌 경우 (case3) 하나의 실수값으로 수렴하고 그 실수값이 $E(S_n/b_n)$ 인 경우로 나눌 수 있다. 

\ck (case3)이 우리가 원하는 WLLN이다. 

\ck (case1)가 가능하다는것 즉 
\[
\frac{S_n}{b_n}=\frac{X_{n,1}+\dots+X_{n,n}}{b_n} \overset{p}{\to} \infty
\]
와 같은 경우가 가능하다는것을 이해하는것은 매우 쉽다.
\[
X_{n,1}=\mbox{weight} \times X_1
\]
이라고 해석할 수 있는데 weight를 악의적으로 주면 (weight들의 총합이 $b_n$보다 훨씬 크게) $S_n/b_n$ 을 쉽게 발산시킬 수 있다. 

\ck (case2)가 가능함을 이해하는것은 쉽지않다. 

\ck WLLN에서 전제되는 중요한 조건들을 요약하면 아래와 같다. 
\one 독립 혹은 무상관 조건
\two 동일한 분포에 대한 조건 (분산만 동일한지, 평균과 분산 모두 같은지, 동일한 분포를 가지는지 등)
\three 모멘트에 대한 조건 (평균이 존재하는지, 분산이 존재하는지 등)

\parared{Lemma 2.2.2} (3) 아래를 만족하는 적당한 $r$을 선택할 수 있다고 하자. 
\[
E\left|\frac{X_{n,1}+\dots+X_{n,n}}{b_n}-\frac{\mu_{n,1}+\dots+\mu_{n,n}}{b_n}\right|^r \overset{p}{\to} 0
\]
그러면 아래와 같은 WLLN이 성립함을 보일 수 있다. 
\[
\frac{X_{n,1}+\dots+X_{n,n}}{b_n} \overset{p}{\to} \frac{\mu_{n,1}+\dots+\mu_{n,n}}{b_n}.
\]

\parared{Theorem 2.2.3.} 
(1) $X_1,X_2,\dots $ 이 \emph{uncorrelated random variables}이다.
(2) $X_1,X_2,\dots $의 평균은 모두 같은 값을 가지지만 분산이 같은 값을 가질필요는 없다. (3) $X_1,X_2,\dots$ 의 분산을 유한한 값 $C$로 바운드시킬 수 있다. 
(1)-(3)의 가정하에 아래와 같은 WLLN이 성립한다. 
\[
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \mu.
\]

\note \textcolor{red}{참고로 이 조건하에서는 $L_2$-convergence도 가능하다.}

\parared{Theorem 2.2.4.} (3) $X_{n,1},\dots,X_{n,n}$의 총합의 분산 즉 $V(X_{n,1}+\dots+X_{n,n})$보다 빠르게 발산하는 어떠한 $b_n^2$을 잡을 수만 있다면, 즉 
\[
\frac{V(X_{n,1}+\dots+X_{n,n})}{b_n^2} \to 0
\]
를 만족하는 $b_n$을 잡을 수 있다면 아래와 같은 WLLN이 성립한다. 
\[
\frac{X_{n,1}+\dots+X_{n,n}}{b_n} \overset{p}{\to} \frac{\mu_{n,1}+\dots+\mu_{n,n}}{b_n}.
\]

\note 조건 $\frac{V(X_{n,1}+\dots+X_{n,n})}{b_n^2} \to 0$는 결국 
\[
V(X_{n,1}+\dots+X_{n,n})=o(b_n^2)
\]
이라는 의미이다. 


\parared{Theorem 2.2.6.} (1) $X_{n,1}, \dots, X_{n,k}$가 서로 독립이다. (3) $X_{n,1},\dots,X_{n,k}$	이 아래의 모멘트 조건들을 동시에 만족한다. 
\begin{align*}
({\star}) & \quad \sum_{k=1}^{n} \int {\bf 1}_{|X_{n,k}|>b_n} dP_k = o(1) \\
(\star\star) & \quad \sum_{k=1}^{n} \int  \frac{1}{b_n^2}X_{n,k}^2{\bf 1}_{|X_{n,k}| \leq b_n}dP_k = o(1)
\end{align*}
이때 $b_n$ 은 양수이고 무한대로 발산하는 수열이다. (1)-(3)의 가정하에 아래가 성립한다. 
\begin{align*}
\frac{X_{n,1}+\dots+X_{n,n} }{b_n} \overset{p}{\to} \frac{\tilde\mu_{n,1}^{b_n}+\dots+\tilde\mu_{n,n}^{b_n}}{b_n}
\end{align*}
여기에서 $\tilde\mu_{n,k}^{b_n}:=E\big(X_{n,k}{\bf 1}_ {|X_{n,k}|\leq b_n } \big)=\int X_{n,k}{\bf 1}_{|X_{n,k}|\leq b_n}dP_k$이다. 

\note 위의 조건 $(\star)$, $(\star\star)$는 Chung의 교재스타일로 정리한것이다. Durret의 노테이션은 아래와 같다. 
\begin{align*}
(\star) &\quad   \sum_{k=1}^{n} P\big(|X_{n,k}|>b_n\big) \to 0 \\
(\star\star) &\quad b_n^{-2}\sum_{k=1}^{n} E \big( X_ {n,k}^2 {\bf 1}_ {|X_{n,k}| \leq b_n} \big) \to 0 
\end{align*}
위에서 엄밀하게 말하면 동일한 $P$로 쓸수 없고 $P_k$로 써야한다. $E$역시 마찬가지이다. 하지만 간결함을 위해서 (그리고 엄밀함을 희생했다) 듀렛책은 이렇게 표현한것 같다. 대부분 듀렛의 노테이션을 따랐지만 \textbf{Thm 2.2.6} 에서만은 Chung의 기호를 빌려왔는데 그 이유는 듀렛책의 표현이 너무 간결하여 의미가 헷갈릴수도 있겠다 싶었기 때문이다. 

\parared{Theorem 2.2.7.} (1)-(2) $X_1, \dots, X_n$이 \textbf{\emph{i.i.d.}}라고 하자. (3) $X_1 \dots X_n$이 아래의 모멘트 조건을 만족한다고 하자. 
\[
xP(|X_1|> x ) \to 0 \mbox{ as } x \to \infty \quad \quad \cdots (\tilde\star)
\]
아래의 WLLN이 성립한다. 
\begin{align*}
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \tilde{\mu}^{n} \quad \mbox{where}\quad \tilde\mu^{n}:=E(X_1 {\bf 1}_{|X_1|\leq n}).
\end{align*}

\note \textbf{Thm 2.2.7.}은 $\frac{X_1+\dots+X_n}{n}$ 의 $p$-수렴성은 보장하지만 그것이 $\mu=EX_1$로 수렴함을 보장하지 않는다. 즉 
\begin{align*}
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \mu
\end{align*}
임을 보장하는것은 아니다. 이게 성립하려면 $\tilde\mu^{n} \to \mu$ 가 성립해야 하고 이는 DCT에 의해서 성립해야하는데 DCT가 성립하려면 $E|X_i|<\infty$ 의 조건이 추가적으로 있어야 한다. (어디로인가 수렴한다고 했지 제 정신 밖힌 값으로 수렴한다고는 안했다!!) 즉 \textbf{Thm 2.2.7}의 조건 아래에서 
\begin{align*}
\frac{X_1 {\bf 1}_ {|X_1| \leq n} +\dots+X_n {\bf 1}_ {|X_n| \leq n} }{n},  \quad \frac{X_1+\dots+X_n}{n}
\end{align*}
모두 같은 $p$-극한을 가진다. 

\parared{Theorem 2.2.9.} (1)-(2) $X_1,\dots,X_n$이 \textbf{\emph{i.i.d.}}라고 하자. (3) 유한평균값이 존재한다고 하자. 즉 
\[
E|X_i|<\infty
\]
이라고 하자. 그러면 아래의 WLLN이 성립한다. 
\begin{align*}
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \mu \quad \mbox{where} \quad \mu:=EX_1.
\end{align*}

\subsection{증명들}

\paragraph{\underline{\LARGE Lemma 2.2.2의 증명}}
\ck 체비쉐프 부등식을 이용하면 된다. 

\paragraph{\underline{\LARGE Theorem 2.2.3의 증명}}
\ck $L_2$ 수렴함을 보이면 된다. 
\[
E\left(\frac{X_1+\dots+X_n}{n}-\mu\right)\leq\frac{Cn}{n^2}=o(1)
\]
이므로 증명끝. 

\paragraph{\underline{\LARGE Theorem 2.2.4의 증명}}
\ck 역시 $L_2$ 수렴함을 보이면 된다. 
\[
E\left(\frac{X_{n,1}+\dots+X_{n,n}}{b_n}-\frac{\mu_{n,1}+\dots+\mu_{n,n}}{b_n}\right)=b_n^{-2}V(X_{n,1}+\dots+X_{n,n})=o(1)
\]
이므로 증명 끝. 

\paragraph{\underline{\LARGE Theorem 2.2.6의 증명}}
\ck 생략.

\paragraph{\underline{\LARGE Theorem 2.2.7의 증명}}
\ck 증명을 위해서 아래의 레마를 외우자. 이걸 증명하는것보다 아래의 레마를 외우는게 더 중요하다. 

\parared{Lemma 2.2.8.} $Y\geq 0$ 이고 $r>0$이면 아래가 성립한다. 
\[
E(Y^r)=\int_0^{\infty}ry^{r-1}P(Y>y)dy.
\]
\note 이 정리에서 $Y$를 양의 확률변수로 한정한 이유는 증명과정에서 푸비니정리를 쓰기 때문이다. 

\ck 조건$(\tilde\star)$에서 $\emph{i.i.d.}$를 쓰면 바로 $(\star)$를 얻을수 있다. 우선 조건$(\tilde\star)$를 살펴보자. 
\[
(\tilde\star): ~xP(|X_1|>x)=o(1) \quad \mbox{as $x \to \infty$} 
\]
$x$대신에 $n$을 대입하자. 
\[
nP(|X_1|>n)=o(1)
\]
이제 \emph{i.i.d.} 조건을 쓰면 아래를 얻을 수 있다. 
\[
\sum_{k=1}^{n}P\left(|X_k|>n\right)=nP\left(|X_1|>n\right)=o(1)
\]
$X_{n,k}=X_k$라고 놓고 $b_n=n$이라고 두면 이것은 \textbf{\textcolor{red}{Thm 2.2.6}}의 셋팅에서 $(\star)$를 보인셈이 된다. 

\ck 이제 $(\star\star)$를 보이자. 즉 아래를 보이면 된다. 
\begin{align*}
&b_n^{-2}\sum_{k=1}^{n}E\left(X_{n,k}^2{\bf 1}_{|X_{n,k}|\leq b_n }\right) \\
&=n^{-2}\sum_{k=1}^{n}E\left(X_{k}^2{\bf 1}_{|X_{k}|\leq n }\right)=n^{-2}nE\left(X_1^2{\bf 1}_{|X_1|\leq n}\right)\\
&=o(1).
\end{align*}

\ck $Y:=X_1{\bf 1}_{|X_1|\leq n}$로 보고 \textbf{\textcolor{red}{Lemma 2.2.8}}을 쓰자. \footnote{$Y:=X_1{\bf 1}_{|X_1|\leq n}$이니까 당연히 $Y^2=X_1^2{\bf 1}_{|X_1|\leq n}$인건 말안해도 괜찮겠지? $\big({\bf 1}_{|X_1|\leq n}\big)^2={\bf 1}_{|X_1|\leq n}$이니까?}
\[
E\left(X_1^2{\bf 1}_{|X_1|\leq n}\right)=EY^2=\int_0^{\infty}2yP(Y>y)dy
\]
그런데 일단 $Y\leq n$ 이므로 $y\geq n$이라면 $P(Y>y)=0$이다.\footnote{잘 모르겠으면 수직선 그려놓고 $Y,n,y$순서로 그려봐} 따라서 적분의 범위를 $[0,\infty]$에서 $[0,n]$으로 좁힐 수 있다. 즉 
\begin{align*}
\int_0^{\textcolor{blue}{\infty}}2yP(Y>y)dy=\int_0^{\textcolor{blue}{n}}2yP(Y>y)dy
\end{align*}
이다. 아래가 성립함을 관찰하라. 
\[
\int_0^{n}2yP(Y>y)dy=\int_0^{n}2yP(X_1{\bf 1}_{|X_1|\leq n}>y)dy\leq\int_0^{n}2yP(X_1>y)dy
\]
따라서 아래를 보이면 증명이 끝난다. 
\[
\frac{1}{n}\int_0^{n}2yP(X_1>y)dy=o(1) \quad \mbox{or} \quad \int_0^{n}2yP(X_1>y)dy=o(n)
\]
이 식은 직관적으로 성립함을 알 수 있다. 왜냐하면 
\[
2yP(X_1>y) = o(1) \quad \mbox{as} \quad y\to \infty
\]
이고 
\[
\frac{1}{n}\int_0^n 2yP(X_1>y)dy
\]
는 $2yP(X_1>y)$의 평균같은 개념이기 때문이다. 

\ck 좀 더 엄밀하게 증명하기 위해서\footnote{to spell out the details} 아래를 주목하라. 
\[
0\leq g(y)\leq 2y, \quad \mbox{where} \quad g(y)=2yP(X_1>y)
\]
아래가 성립한다. 
\[
g(y)=o(1)
\]
$o(1)$이면 $O(1)$이니까 아래가 성립한다. 
\[
\sup_y g(y) =M <\infty
\]
아래를 정의하자. 
\[
\epsilon_K=\sup_{y > K} g(y)
\]
그리고 $[0,K]$까지의 적분과 $[K,n]$까지의 적분을 따로 생각하자.\footnote{consider A and B seperately}
\[
\int_0^{n}2yP(|X_1|>y)dy \leq KM +(n-K)\epsilon_K
\]
양변을 $n$으로 나누고 $n\to \infty$를 취하자. 그러면\footnote{Dividing by $n$ and letting $n\to\infty$, we have}
\[
\limsup_{n\to\infty}\frac{1}{n}\int_0^n2yP(|X_1|>y)dy\leq\epsilon_K
\]
가 성립한다.\footnote{굳이 $\limsup$을 쓸 필요는 없어보인다. $\lim$만 써도 충분한듯. 하지만 $\limsup$으로 쓸 수 있어서 그냥 쓴 것 같다.} $K$가 arbitary이고 $\epsilon_K \to 0 ~\mbox{as}~ K\to\infty$이므로 원하는 결론을 얻을 수 있다.
\footnote{$K$가 $K<n$인 조건하에서는 아무렇게나 선택할 수 있다는 의미는 (1) $n$을 무한대로 보낼때 $K$도 그에 맞춰서 무한대로 가면서 (2) $K/n \to 0 ~ as ~ n\to\infty$ 를 만족하도록 적당히 정할 수 있다는 의미이다. 이는 매우 \textcolor{red}{편리한} 성질이다. 풀이과정중 $\frac{KM}{n}$을 0으로 수렴시키게 할 수 있는것은 (2)의 성질을 이용한 것이다. 또한 $\epsilon_K=o(n)$임을 보일때 $\epsilon_K=o(K)$임을 대신 보여도 충분한 것은 (1)의 성질 때문이다.}

\note 증명의 뒷부분의 논리를 좀 더 내 방식으로 해석해보자. 아래를 정의하자. 
\[
\epsilon_{K_n}=\sup_{y>K_n}g(y)
\]
여기에서 수열 $K_n$은 아래의 성질을 만족한다. 
\begin{align*}
\begin{cases}
K_n < n \quad \mbox{for all} \quad n \\ 
K_n\to\infty \quad as \quad n\to\infty \\
\frac{K_n}{n}=o(1) \quad as \quad n\to\infty
\end{cases}
\end{align*}
즉 $\{K_n\}$이 $n$이 무한대로 갈때 그에 맞추어서 점점 무한대로 가는 (하지만 항상 $K_n<n$인) 어떠한 수열이다. \footnote{조건 $(\tilde\star)$에 의해서 $\epsilon_{K_n}=o(1)~ as~ n\to\infty$ 가 성립함} 
그리고 $[0,K_n]$까지의 적분과 $[K_n,n]$까지의 적분을 따로 생각하자. 
\[
\int_0^{n}2yP(|X_1|>y)dy \leq K_nM +(n-K_n)\epsilon_{K_n}
\]
양변을 $n$으로 나누면 
\[
\frac{1}{n}\int_0^n2yP(|X_1|>y)dy\leq\frac{K_nM}{n}+\epsilon_{K_n}-\frac{1}{n}=\epsilon_{K_n}+o(1) \quad \mbox{as}\quad n\to\infty
\]
와 같이 된다. 그런데 
\[
\epsilon_{K_n}=o(1) \quad \mbox{as}\quad n\to\infty 
\]
이므로 증명이 끝난다. 

\note 이게 어심토틱에 나오는 증명의 묘미이다. $y$에 대한 극한조건을 교묘하게 $n$ 혹은 $K$ 대한 극한조건으로 바꾸어서 증명한다. 

\paragraph{\underline{\LARGE Theorem 2.2.9의 증명}}


\ck 확률변수가 유한평균값을 가지므로 아래가 성립한다. 
\begin{align*}
(\tilde\star):\quad xP(|X_1|> x ) \to 0 \quad \mbox{ as } x \to \infty 
\end{align*}
참고로 위의 식이 성립하는 이유는 
\[
xP(|X_1|> x ) \leq E( |X_1|{\bf 1}_ {|X_1|>x} ) \to 0
\]
이기 때문이다. 왼쪽의 부등호는 적분꼴로 쓰면 바로 이해가능하고 오른쪽의 극한은 DCT에 의해서 성립한다. 아무튼 조건 $(\star)$ 가 성립하므로 \textbf{\textcolor{red}{Thm 2.2.7}}을 쓰면 
\begin{align*}
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \tilde{\mu}^{n}:=E(X_1 {\bf 1}_ {|X_1|\leq n}) \mbox{ as } n \to \infty 
\end{align*} 
가 성립한다. 그런데 아래의 식이 성립한다. (DCT에 의해서 성립함) 
\begin{align*}
\tilde\mu^{n}:=E(X_1 1_ {|X_1|\leq n}) \to \mu:=EX_1 \mbox{ as } n \to \infty 
\end{align*}
이제 $S_n / n \overset{p}{\to} \tilde{\mu}^{n}$ 와 $\tilde{\mu}^{n}\to \mu$ 임을 이용하면 아래가 성립함을 알 수 있다. ($o_p(1)+o(1)=o_p(1)$ 이므로 성립.)
\begin{align*}
\frac{X_1+\dots+X_n}{n} \overset{p}{\to} \mu. 
\end{align*}

\ck 증명과정에서 기억할만한 것은 확률변수가 유한평균값을 가진다는 것이 아래를 임플라이 한다는 것이다. 
\begin{align*}
(\tilde\star):\quad xP(|X_1|> x ) \to 0 \quad \mbox{ as } x \to \infty 
\end{align*}
반대로 위 조건(앞으로 편의상 조건 $(\tilde\star)$ 라고 부르자)이 유한평균값을 가짐을 임플라이 하지는 못한다. 따라서 조건 $(\tilde\star)$은 유한평균값을 가진다는 조건보다 약한 조건이다. 하지만 조건 $(\tilde\star)$ 은 확률변수가 유한평균값을 가진다는 조건보다 정말 말 그대로 $\epsilon$ 만큼만 약한 조건이다. 구체적으로는 조건 $(\tilde\star)$ 이 만족하면 아래를 임플라이 할 수 있다. 
\begin{align*}
(\tilde\star) \quad \Longrightarrow \quad \forall \epsilon>0: ~ E|X_1 |^{1-\epsilon} < \infty
\end{align*}
이것의 증명은 \textbf{\textcolor{red}{Lemma 2.2.8}}을 이용해서 할 수 있다. \textbf{따라서 조건 $(\tilde\star)$ 는 유한평균값을 가진다는 조건에 비하여 많이 부족한 조건은 아니다. 사실상 거의 대등하다고 보아도 무방하다.}

\note 조건 $(\tilde\star)$와 \textbf{\emph{uniformly tight}}를 헷갈렸었다. (진짜 아는게 없어서 오만걸 다 헷갈리네) 내가 헷갈린 타이트조건은 아래와 같이 쓸 수 있다. 
\begin{align*}
& \mbox{$\{X_n\}$ is \emph{uniformly tight}} \\
& \overset{def}{\Longleftrightarrow} \forall \epsilon>0 \quad \exists M \quad s.t. \quad \sup_nP(|X_n|>M)<\epsilon \\ 
& \overset{def}{\Longleftrightarrow} \sup_n P(|X_n|>M) \to 0 \quad as ~ M\to \infty \\ 
& \overset{def}{\Longleftrightarrow} \sup_n\mu_n^{\star}\big([-M,M]^c\big) \to 0 \quad as ~ M \to \infty \\ 
& \overset{def}{\Longleftrightarrow} \epsilon>0 \quad \exists M \quad s.t. \quad \limsup_{n\to\infty} \big(1-F_n(M)+F_n(-M)\big) < \epsilon \\ 
& \overset{def}{\Longleftrightarrow} X_n=O_p(1) \quad as ~ n\to\infty 
\end{align*}

\note 보통 유니폼리-타잇니스도 그냥 줄여서 타잇니스라고 말하기도 한다. 

\note 모든 확률변수는 \emph{tight}하다.\footnote{타이트의 정의는 아래와 같다. 
\begin{align*}
& \mbox{The random variable $X$ is \emph{tight}} \\
& \overset{def}{\Longleftrightarrow} \forall \epsilon>0 \quad \exists M \quad s.t. \quad P(|X|>M)<\epsilon \\ 
& \overset{def}{\Longleftrightarrow} P(|X|>M) \to 0 \quad as ~ M\to \infty \\ 
& \overset{def}{\Longleftrightarrow} \mu^{\star}\big([-M,M]^c\big) \to 0 \quad as ~ M \to \infty \\ 
& \overset{def}{\Longleftrightarrow} \epsilon>0 \quad \exists M \quad s.t. \quad 1-F(M)+F(-M) < \epsilon 
\end{align*}} 하지만 모든 확률변수열이 \emph{uniformly tight} 하지는 않다. \footnote{확률변수열이 \emph{uniformly tight} 하다는 말은 확률변수열이 유계라는 말과 같다. Van der Vaart (2000)의 p.8.}

\section{Borel-Cantelli Lemmas}
\subsection{set-theory}

\ck 듀렛교재와 더불어 인터넷을 참고해보자.\footnote{[1] \url{http://theanalysisofdata.com/probability/A_4.html}, [2] \url{https://en.wikipedia.org/wiki/Set-theoretic_limit}}
\one $\sup_{k\geq n}A_k=\cup_{k=n}^{\infty}A_k$. \footnote{여기에서 $\sup_{k\geq n}A_k$는 sequence of $n$임을 유의하자. 즉 $\sup_{k\geq n}A_k=B_n$ 과 같이 놓을 수 있다. 하지만 $k$에 대한 sequence는 아니기 때문에 $\sup_{k\geq n}A_k=B_k$와 같이 놓을 수는 없다.}
\two $\inf_{k\geq n}A_k=\cap_{k=n}^{\infty}A_k$. 
\three $\underset{n\to\infty}{\limsup}A_n=\underset{n\to\infty}{\lim}\sup_{k\geq n}A_k=\underset{n\to\infty}{\lim}\cup_{k=n}^{\infty}A_k=\cap_{n=1}^{\infty}\cup_{k=n}^{\infty}A_k$. \footnote{마지막등호는 $\cup_{k=n}^{\infty}A_k:=B_n$이 $n$에 대한 monotone sequence이기 때문에 성립한다.}
\four $\underset{n\to\infty}{\liminf}A_n=\underset{n\to\infty}{\lim}\inf_{k\geq n}A_k=\underset{n\to\infty}{\lim}\cap_{k=n}^{\infty}A_k=\cup_{n=1}^{\infty}\cap_{k=n}^{\infty}A_k$. 

\ck $A_n$이 $\Omega$의 부분집합으로 이루어진 집합열이라고 한다면, 아래와 같이 둘 수 있다. \footnote{If $A_n$ is subset of sequence of $\Omega$, we let}
\one $\underset{n\to\infty}{\limsup}A_n=\bigg\{\omega\in \Omega: \sum_{n=1}^{\infty} I(\omega \in A_n) = \infty\bigg\}=\bigg\{\omega: \omega\in A_n, i.o.\bigg\}$
\two $\underset{n\to\infty}{\liminf}A_n=\bigg\{\omega\in \Omega: \sum_{n=1}^{\infty} I(\omega \in A_n) < \infty\bigg\}=\bigg\{\omega: \omega\in A_n, a.b.f.\bigg\}$

\ex $X_1,X_2,\dots $이 베르누이열이라고 하자. \footnote{즉 $X_1,X_2,\dots$의 가능한 realization은 $0,1,\dots$ 이다.} 그리고 $(\Omega_1,{\cal F}_1,P_1)$을 $X_1$에 대응하는 확률공간이라고 하자. 콜모고로프정리에 따라서 랜덤벡터 $(X_1,X_2,\dots, )$가 정의되는 공간 $(\Omega,{\cal F})$를 정의할 수 있다. \footnote{즉 $\Omega:=\Omega_1\times\Omega_2\times \dots $ 이고 ${\cal F}:={\cal F}_1\times {\cal F}_2 \times \dots$.} 이제 $S_n/b_n=\frac{1}{n}\sum_{i=1}^{n}X_i$ 라고 하자. 이제 
\[
A_n=\Big\{\omega\in \Omega : |S_n(\omega)/b_n-1/2| > \epsilon \Big\}
\] 
라고 정의하자. \footnote{$A_n$은 $\epsilon$에 따라 변화하는 함수인데 이를 강조하기 위해서 $A_n(\epsilon)$이라고 표시할 수도 있다.} 그러면 
\[
\sup_{\epsilon>0} \bigg\{\underset{n\to\infty}{\limsup} A_n\bigg\} = \bigg\{\mbox{$0$보다 $1$의 숫자가 \textcolor{red}{일정한 비율로} 많은 모든 이벤트}\bigg\}
\]
이다. 
\note $\underset{\epsilon>0}{\sup}~ \Big\{\underset{n\to\infty}{\limsup} A_n\Big\}$의 원소로 어떤것이 있을지 알아보자. 빨간색글자는 copy and paste 로 반복된다고 하자.
\begin{align*}
(1): &\quad  \big\{1,~|~\textcolor{red}{1,0, ~|~ 1,0, ~|~, \dots}\big\} \\
(2): &\quad \big\{1,1,~|~\textcolor{red}{1,0, ~|~ 1,0, ~|~, \dots}\big\} \\
(3): &\quad \big\{1,1,1,~|~\textcolor{red}{1,0, ~|~ 1,0, ~|~, \dots}\big\} \\
(4): &\quad \big\{\textcolor{red}{1,\overset{\times 100 }{\overbrace{1,0,1,0,1,0,1,0,\dots,1,0}},~|~1,\overset{\times 100 }{\overbrace{1,0,1,0,1,0,1,0,\dots,1,0}},~|~,\dots}\big\} \\
\end{align*}
(1)-(3)의 경우는 $\underset{\epsilon>0}{\sup}~ \Big\{\underset{n\to\infty}{\limsup} A_n\Big\}$의 원소이지만 (4)의 경우는 아니다.\footnote{왜냐하면 (4)의 경우는 $\epsilon=\frac{1}{101}$ 보다 크면 $\underset{n\to\infty}{\limsup} A_n$의 원소이지만 $\epsilon=\frac{1}{101}$ 보다 작으면 $\underset{n\to\infty}{\limsup} A_n$의 원소가 아니기 때문이다.}

\section{Poisson Convergence}
\parared{Theorem} Each $n$ 에 대하여 $X_{n,m},~ 1\leq m \leq n$ 이 서로 독립인 확률변수라고 하자. 그리고 $P(X_{n,m}=1)=p_{n,m}$ 이고 $P(X_{n,m}=0)=1-p_{n,m}$이라고 하자. (1) $\sum_{m=1}^{n}p_{n,m} \to \lambda ~ as ~ n\to\infty$ (2) $\max_{1\leq m \leq n} p_{n,m}\to 0~ as ~ n\to\infty$ 이라면 아래가 성립한다. 
\[
S_n \Rightarrow Z \quad \mbox{where $Z$ is Poisson($\lambda$).}
\]
\note 이항분포의 포아송근사. 일단 독립인 랜덤변수들의 합의 분포를 다루는것임. 
\subsection{Two Example with Dependence}
\ck 독립이 아닌경우에서도 포아송으로 근사할 수 있다는 예제들을 설명한 챕터인듯. 

\section{Limit Theorems in $\mathbb{R}^d$}
\para{exercise} $F_1,\dots,F_d$가 $\mathbb{R}$에서 정의되는 distribution이라고 하자. \footnote{Let $F_1,\dots,F_d$ be the distributions on $\mathbb{R}$.} 그러면 임의의 $\alpha=[-1,1]$에 대하여 
\[
F(x_1,\dots,x_d)=\bigg\{1+\alpha\prod_{i=1}^{d}(1-F_i(x_i))\bigg\}\prod_{j=1}^dF_j(x_j)
\]
역시 d.f. 이고 $F(x_1,\dots,x_d)$의 마지날은 각각 $F_1,\dots,F_d$와 같다. 이때 $\alpha=0$은 $\bsX=(X_1,\dots,X_d)^\top$ 의 각 원소가 독립인 경우를 의미한다. 

\end{document}

