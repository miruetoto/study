---
title: (강의) 부분자기상관계수
layout: post
---


### About this doc

- 시계열 강의노트를 각색하여 만듬. 

- 부분자기상관계수의 내용을 다룸. 

- 학부수준. (고학년 학부수준)


### 예비학습 1

- **(정리1)** $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
cov(Y-E(Y\|X),u(X))=0 
\end{align}


- **(정리2)** $X$,$Y$가 확률변수라고 하자. 그러면 모든 $u(X)$에 대하여 아래가 성립한다. 
\begin{align}
E\big[(Y-E(Y\|X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
여기에서 $E(Y\|X)$는 best predictor of $Y$ given $X$ 라고 하자. 

- 편의상 $E(Y|X)$를 $\hat{Y}^{BP\|X}$라고 정의하자. 즉 
\begin{align}
\hat{Y}^{BP\|X}=E(Y|X)
\end{align}
이다. 

- 반대로 우리가 찾은 어떠한 $u^* (X)$가 모든 $u(X)$에 대하여 
\begin{align}
E\big[(Y-u^* (X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
를 만족한다면 $u^* (X)=E(Y|X)$라고 주장할 수 있다. 

--- 


### 예비학습 2 

- $X$, $Y$ 가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+\beta_1 X+\epsilon
\end{align}
우리의 관심사는 아래를 구하는 것이다. 
\begin{align}
\underset{\beta_0,\beta_1}{\operatorname{argmin} } E\big[(Y-\beta_0-\beta_1 X)^2\big]
\end{align}

- 편의상 
\begin{align}
E\big[(Y-\beta_0-\beta_1 X)^2\big]
\end{align}
를 최소화 하는 특정한 $\beta_0$와 $\beta_1$을 각각 $\hat\beta_0^{BP\|X},\hat\beta_1^{BP\|X}$라고 하자. 즉 
\begin{align}
\boldsymbol{\hat\beta}^{BP\|X}=
\begin{bmatrix}
\hat\beta_0^{BP\|X} \\\\ \\
\hat\beta_1^{BP\|X}
\end{bmatrix}= \underset{\beta_0,\beta_1}{\operatorname{argmin} } E\big[(Y-\beta_0-\beta_1 X)^2\big] 
\end{align}
이다. 

- 아무튼 
\begin{align}
\underset{\beta_0,\beta_1}{\operatorname{argmin} } E\big[(Y-\beta_0-\beta_1 X)^2\big]
\end{align}
를 풀기 위해서는 아래를 연립하여 풀면 된다. 
\begin{align}
\frac{1}{\partial\beta_0} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0 \\\\ \\
\frac{1}{\partial\beta_1} E\big[(Y-\beta_0-\beta_1 X)^2\big]=0
\end{align}
미분을 expectation 안으로 넣으면 
\begin{align}
E\big[-2(Y-\beta_0-\beta_1 X)\big]=0 \\\\ \\
E\big[-2X(Y-\beta_0-\beta_1 X)\big]=0
\end{align}
와 같이 된다. 두번째식을 풀면 
\begin{align}
\beta_1EX^2=EXY-\beta_0EX.
\end{align}
첫 번째식을 두 번째에 대입하면 
\begin{align}
\beta_1EX^2=EXY-(EY-\beta_1EX)EX=EXY-EXEY+\beta_1(EX)^2.
\end{align}
따라서 
\begin{align}
\hat\beta_1^{BP\|X}=&\frac{EXY-(EX)(EY)}{EX^2-(EX)^2}=\frac{cov(X,Y)}{V(X)} \\\\ \\
\hat\beta_0^{BP\|X}=&EY-\frac{cov(X,Y)}{V(X)}EX.
\end{align}
이다. 

- 아래의 식을 만족하는 $u^* (X)$를 정의하자. 
\begin{align}
u^* (X)=\hat\beta_0^{BP\|X}+X\hat\beta_1^{BP\|X}
\end{align}
$u^* (X)$는 임의의 $u(X)$에 대하여 
\begin{align}
E\big[(Y-u^* (X))^2\big]\leq E\big[(Y-u(X))^2\big]
\end{align}
를 만족한다. 따라서 예비학습 2 의 결과를 활용하면 아래와 같이 쓸 수 있다. 
\begin{align}
\hat{Y}^{BP\|X}=\hat\beta_0^{BP\|X}+X\hat\beta_1^{BP\|X}=E(Y\|X)
\end{align}

- 결국 $E(Y\|X)$는 $Y$를 $X$에 회귀시켜 얻은 예측값으로 볼 수 있다. 이런 이유로 교재에서는 $E(Y\|X)$를 ''$Y$를 $X$에 회귀시킨 최적선형예측값'' 이라고 부른다. 이제 
\begin{align}
Y^* = Y-E(Y\|X)
\end{align}
라고 정의하면 $Y^* $는 ''$Y$를 $X$에 회귀시킨후에 얻은 잔차''로 해석할 수 있다. 

---

### 예비학습 3

- $X_1$, $X_2$, $Y$ 가 확률변수라고 하자. 아래와 같은 모델을 가정하자. 
\begin{align}
Y=\beta_0+X_1\beta_1+ X_2\beta_2+\epsilon
\end{align}
우리의 관심사는 아래를 구하는 것이다. 
\begin{align}
\boldsymbol{\hat\beta}^{BP\|X_1,X_2}=\underset{\beta_0,\beta_1,\beta_2}{\operatorname{argmin} } E\big[(Y-\beta_0-\beta_1 X_1-\beta_2 X_2)^2\big]
\end{align}

- 이를 위해서는 아래를 연립하여 풀면 된다. 
\begin{align}
\begin{cases}
\frac{1}{\partial\beta_0} E\big[(\dots)^2\big]=0 \\\\ \\
\frac{1}{\partial\beta_1} E\big[(\dots)^2\big]=0 \\\\ \\
\frac{1}{\partial\beta_2} E\big[(\dots)^2\big]=0
\end{cases}
\end{align}
미분을 expectation 안으로 넣으면 
\begin{align}
\begin{cases}
E\big[-2(Y-\beta_0-\beta_1 X_1-\beta_2 X_2)\big]=0 \\\\ \\
E\big[-2X_1(Y-\beta_0-\beta_1 X_1-\beta_2 X_2)\big]=0 \\\\ \\
E\big[-2X_2(Y-\beta_0-\beta_1 X_1-\beta_2 X_2)\big]=0
\end{cases}
\end{align}
와 같이 된다. 정리하면 아래와 같이 된다. 
\begin{align}
\begin{bmatrix}
1 & EX_1 & EX_2 \\\\ \\
EX_1 & EX_1^2 & EX_1X_2 \\\\ \\
EX_2 & EX_1X_2 & EX_2^2 
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\\\ \\
\beta_1 \\\\ \\
\beta_2
\end{bmatrix}
=
\begin{bmatrix}
EY \\\\ \\
EX_1Y \\\\ \\
EX_2Y
\end{bmatrix}
\end{align}
이는 다시 아래처럼 쓸 수 있다. 
\begin{align}
\begin{bmatrix}
1 & EX_1 & EX_2 \\\\ \\
0 & V(X_1) & cov(X_1,X_2) \\\\ \\
0 & cov(X_1,X_2) & V(X_2)
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\\\ \\
\beta_1 \\\\ \\
\beta_2
\end{bmatrix}
=
\begin{bmatrix}
EY \\\\ \\
cov(X_1,Y) \\\\ \\
cov(X_2,Y)
\end{bmatrix}
\end{align}
결국 원하는 해를 구하기 위해서는 아래를 연립하면 된다. 
\begin{align}
\begin{cases}
\beta_0+EX_1\beta_1+EX_2\beta_2 = EY \\\\ \\ 
\begin{bmatrix}
V(X_1) & cov(X_1,X_2) \\\\ \\
cov(X_1,X_2) & V(X_2) 
\end{bmatrix}
\begin{bmatrix}
\beta_1 \\\\ \\
\beta_2
\end{bmatrix}
=
\begin{bmatrix}
cov(X_1,Y) \\\\ \\
cov(X_2,Y)
\end{bmatrix}
\end{cases}
\end{align}

- $X_1,X_2,\dots,X_p$인 일반적인 경우에도 유사한 논리가 성립한다. 즉 
\begin{align}
\boldsymbol{\hat\beta}^{BP\|X_1,X_2,\dots,X_p}
\end{align}
를 구하기 위해서는 아래를 연립하면 된다. 
\begin{align}
\begin{cases}
\beta_0+EX_1\beta_1+EX_2\beta_2+\dots+EX_p\beta_p = EY \\\\ \\ 
\begin{bmatrix}
V(X_1) & cov(X_1,X_2) & \dots & cov(X_1,X_p) \\\\ \\
cov(X_2,X_1) & V(X_2) & \dots & cov(X_2,X_p) \\\\ \\ 
\dots & \dots & \dots & \dots \\\\ \\
cov(X_p,X_1) & cov(X_p,X_2) & \dots & V(X_p) 
\end{bmatrix}
\begin{bmatrix}
\beta_1 \\\\ \\
\beta_2 \\\\ \\
\dots \\\\ \\
\beta_p
\end{bmatrix}
=
\begin{bmatrix}
cov(X_1,Y) \\\\ \\
cov(X_2,Y) \\\\ \\
\dots \\\\ \\
cov(X_p,Y)
\end{bmatrix}
\end{cases}
\end{align}

---

### AR(1)

- 정상인 AR(1) 모델을 가정하자. 즉 
\begin{align}
Z_t=\phi Z_{t-1}+\epsilon_t. 
\end{align}

- 이때 $E\big[(Z_t-\phi Z_{t-1})^2\big]$을 최소화하는 $\phi$ 를 $\hat\phi^{BP\|Z_{t-1} }$ 라고 하면 
\begin{align}
\hat\phi^{BP\|Z_{t-1} }=\frac{E(Z_tZ_{t-1})}{E(Z_{t-1}^2)}
\end{align}
이 된다. 그리고 
\begin{align}
Z_t - E(Z_t \| Z_{t-1})= Z_t-\hat\phi^{BP\|Z_{t-1} }Z_{t-1}
\end{align}
이 된다. 

--- 

### AR(2) 

- 정상인 AR(2)모델을 가정하자. 즉 
\begin{align}
Z_t=\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+\epsilon_t. 
\end{align}

- 이제 $\hat\phi_1^{BP\|Z_{t-1},Z_{t-2} }$, $\hat\phi_2^{BP\|Z_{t-1},Z_{t-2} }$을 구하기 위해서 아래를 풀어보자. 
\begin{align}
\min_{\phi_1,\phi_2} (Z_t-\phi_1 Z_{t-1}-\phi_2 Z_{t-2})^2
\end{align}
미분을 기대값안으로 넣을 수 있다고 가정하면, 
\begin{align}
\frac{1}{\partial \phi_1}E\big[(\dots)^2]=0 \Longleftrightarrow E\big[-2Z_{t-1}(Z_t-\phi_1 Z_{t-1}-\phi_2 Z_{t-2})\big]=0 \\\\ \\
\frac{1}{\partial \phi_2}E\big[(\dots)^2]=0 \Longleftrightarrow E\big[-2Z_{t-2}(Z_t-\phi_1 Z_{t-1}-\phi_2 Z_{t-2})\big]=0
\end{align}
와 같이 된다. 각각 정리하면 
\begin{align}
\phi_1E(Z_{t-1}^2)+\phi_2E(Z_{t-2}Z_{t-1})=E(Z_tZ_{t-1}) \\\\ \\
\phi_1E(Z_{t-1}Z_{t-2})+\phi_2E(Z_{t-2}^2)=E(Z_{t-2}Z_t)
\end{align}
이를 매트릭스 형태로 표현하면 아래와 같다. 
\begin{align}
\begin{bmatrix}
E(Z_{t-1}^2) & E(Z_{t-2}Z_{t-1}) \\\\ \\
E(Z_{t-1}Z_{t-2}) & E(Z_{t-2}^2)
\end{bmatrix}
\begin{bmatrix}
\phi_1 \\\\ \\
\phi_2
\end{bmatrix}=
\begin{bmatrix}
E(Z_tZ_{t-1}) \\\\ \\
E(Z_{t-2}Z_t)
\end{bmatrix}. 
\end{align}
정리하면 아래와 같이 쓸 수 있다. 
\begin{align}
\begin{bmatrix}
\gamma_1 \\\\ \\
\gamma_2
\end{bmatrix}=
\begin{bmatrix}
\gamma_0 & \gamma_1 \\\\ \\
\gamma_1 & \gamma_0
\end{bmatrix}
\begin{bmatrix}
\phi_1 \\\\ \\
\phi_2
\end{bmatrix}
\end{align}

- 이것은 Yule-Walker 방정식과 형태가 같다. 따라서 
\begin{align}
\begin{cases}
\hat\phi_1^{BP\|Z_{t-1},Z_{t-2} }=\phi_{21}=\phi_1 \\\\ \\
\hat\phi_2^{BP\|Z_{t-1},Z_{t-2} }=\phi_{22}=\phi_2
\end{cases}
\end{align}
와 같이 된다. 

--- 

### AR(2) 

- 다시 정상인 AR(2)모델을 가정하자. 
\begin{align}
Z_t=\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+\epsilon_t. 
\end{align}
이제 아래와 같은 순서로 $\phi_2$의 추정량을 구한다고 가정하자. <br/><br/>
(1) $Z_t$를 $Z_{t-1}$에 회귀시키자. 그 후 잔차를 $Z_t^* $라고 하자. <br/>
(2) $Z_{t-2}$를 $Z_{t-1}$에 회귀시키자. 잔차를 $Z_{t-2}^* $라고 하자. <br/>
(3) (1)의 잔차를 (2)에 회귀시키자. 즉 $Z_t^* $를 $Z_{t-2}^* $에 회귀시키자. 그리고 $Z_{t-2}^* $의 계수를 $\phi_2^* $라고 하자. <br/><br/> 
그러면 아래가 성립한다. 
\begin{align}
\phi_2^* = \hat\phi_{22}
\end{align}

- 증명을 하여보자. 
(1)의 결과는 아래와 같다. 
\begin{align}
Z_t^* =Z_t-\frac{cov(Z_t,Z_{t-1})}{V(Z_{t-1})}Z_{t-1}
\end{align}
(2)의 결과는 아래와 같다. 
\begin{align}
Z_{t-2}^* =Z_{t-2}-\frac{cov(Z_{t-2},Z_{t-1})}{V(Z_{t-1})}Z_{t-1}
\end{align}
따라서 
\begin{align}
\phi_2^* =\frac{cov(Z_{t}^* ,Z_{t-2}^*  )}{V(Z_{t-2}^* )}
\end{align}
가 된다. 분모를 정리하면 
\begin{align}
V(Z_{t-2}^* )=V(Z_{t-2} )+\left[\frac{cov(Z_t,Z_{t-1})}{V(Z_{t-1})}\right]^2V(Z_{t-1})=\gamma_0+\frac{\gamma_1^2}{\gamma_0}
=\frac{\gamma_0^2-\gamma_1^2}{\gamma_0}
\end{align}
분자를 정리하면 
\begin{align}
cov(Z_{t}^* ,Z_{t-2}^* )=&
cov(Z_t,Z_{t-2})\\\\ \\
-& \left[\frac{cov(Z_{t-2},Z_{t-1})}{V(Z_{t-1})}\right]cov(Z_t,Z_{t-1}) \\\\ \\
-& \left[\frac{cov(Z_{t},Z_{t-1})}{V(Z_{t-1})}\right]cov(Z_{t-1},Z_{t-2})\\\\ \\
+& \left[\frac{cov(Z_{t},Z_{t-1})}{V(Z_{t-1})}\right]\left[\frac{cov(Z_{t-2},Z_{t-1})}{V(Z_{t-1})}\right]cov(Z_{t-1},Z_{t-1})
\end{align}
좀 더 정리하면 
\begin{align}
cov(Z_t^* , Z_{t-2}^* )=\gamma_2-\frac{\gamma_1}{\gamma_0}\gamma_1-\frac{\gamma_1}{\gamma_0}\gamma_1+\frac{\gamma_1}{\gamma_0}\frac{\gamma_1}{\gamma_0}\gamma_0
=\frac{\gamma_2\gamma_0-\gamma_1^2}{\gamma_0}
\end{align}
따라서 
\begin{align}
\phi_2^* =\phi_{22}
\end{align}
가 된다. 
또한 
\begin{align}
\begin{cases}
V(Z_t)=V(Z_t-\mu) \\\\ \\
cov(Z_t,Z_{t-1})=cov(Z_{t-1}-\mu,Z_t-\mu)
\end{cases}
\end{align}
임을 활용하면 
\begin{align}
\phi_2^* =\frac{
E\left[\big(Z_t-E(Z_t\|Z_{t-1})\big)\big(Z_{t-2}-E(Z_{t-2}\|Z_{t-1})\big)\right]
}{
\left(E\left[Z_t-E(Z_t\|Z_{t-1})\right]E\left[Z_{t-2}-E(Z_{t-2}\|Z_{t-1})\right]\right)^{1/2}
}
\end{align}
임을 쉽게 확인할 수 있다. 

- 이를 정리하면 정상인 AR(2) 모델에서 $PACF(2)=corr(Z_t,Z_{t-2}\|Z_t)$를 구하는 방법은 아래와 같이 2개의 방법이 있음을 알 수 있다. <br/><br/>
**(방법1)** $Z_t$를 $(Z_{t-1},Z_{t-2})$에 회귀시킨 뒤 $Z_{t-2}$의 계수를 구함. <br/>
**(방법2)** (1) $Z_t$를 $Z_{t-1}$ 에 적합시킨뒤 res를 구함. 즉 $Z_t-E(Z_t\|Z_{t-1})$을 구함. (2) $Z_{t-2}$를 $Z_{t-1}$에 적합시킨뒤 res를 구함. 즉 $Z_{t-2}-E(Z_{t-2}\|Z_{t-1})$를 구함. (3) (1)을 (2)로 적합시킨뒤에 (2)의 계수를 구함. 

- 참고로 AR(2) 모델에서 $PACF(1)=corr(Z_t,Z_{t-1})=ACF(1)$이므로 따로 구하는 방법을 논의할 필요가 없다. 

- (연습문제 5.6) 정상시계열 $Z_t$에 대하여 아래를 각각 정의하자. 
\begin{align}
\begin{cases}
E(Z_t\|Z_{t+1},\dots,Z_{t+h-1})&=&\alpha_1 Z_{t+1}+\dots+\alpha_{h-1}Z_{t+h-1} \\\\ \\
E(Z_{t+h}\|Z_{t+1},\dots,Z_{t+h-1})&=&\beta_{1}Z_{t+h-1}+\dots+\beta_{h-1} Z_{t+1}
\end{cases}
\end{align}
이제 아래식을 이용하면 바로 원하는 결과를 얻는다. 
\begin{align}
\begin{bmatrix}
V(X_1) & cov(X_1,X_2) & \dots & cov(X_1,X_p) \\\\ \\
cov(X_2,X_1) & V(X_2) & \dots & cov(X_2,X_p) \\\\ \\ 
\dots & \dots & \dots & \dots \\\\ \\
cov(X_p,X_1) & cov(X_p,X_2) & \dots & V(X_p) 
\end{bmatrix}
\begin{bmatrix}
\beta_1 \\\\ \\
\beta_2 \\\\ \\
\dots \\\\ \\
\beta_p
\end{bmatrix}
=
\begin{bmatrix}
cov(X_1,Y) \\\\ \\
cov(X_2,Y) \\\\ \\
\dots \\\\ \\
cov(X_p,Y)
\end{bmatrix}
\end{align}

--- 

### AR(1)의 이론적 PACF

- 이제 AR(1) 과정에서의 PACF의 이론적인 형태를 알아보자. 편의상 $E(Z_t)=0$이라고 가정하자. 즉 
\begin{align}
Z_t=\phi Z_{t-1}+\epsilon_t
\end{align}
이다. 

- 양변에 $Z_{t-1},Z_{t-2}$를 곱하고 평균을 취하면 아래가 얻어진다. 
\begin{align}
\gamma_1 =\phi \gamma_0 \\\\ \\ 
\gamma_2 =\phi \gamma_1 \\\\ \\
\cdots
\end{align}
이제 PACF를 구해보자. 
\begin{align}
\phi_{11}=&\phi \\\\ \\
\phi_{22}=&\frac{\begin{vmatrix}  \gamma_0 & \gamma_1 \\\\ \\ \gamma_1 & \gamma_2 \end{vmatrix} }{\begin{vmatrix}  \gamma_0 & \gamma_1 \\\\ \\ \gamma_1 & \gamma_0 \end{vmatrix} }=0 
\end{align}
$\phi_{22}=0$인 이유는 
\begin{align}
\begin{vmatrix}  \gamma_0 & \gamma_1 \\\\ \\ \gamma_1 & \gamma_2 \end{vmatrix} = \begin{vmatrix}  \gamma_0 & \gamma_0\phi \\\\ \\ \gamma_0\phi & \gamma_0\phi^2 \end{vmatrix}=0
\end{align}
이기 때문이다. 

### AR(2)의 이론적 PACF

- 이제 AR(2) 과정에서의 PACF의 이론적인 형태를 알아보자. 편의상 $E(Z_t)=0$이라고 가정하자. 즉 
\begin{align}
Z_t=\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+\epsilon_t
\end{align}
이다. 

- 양변에 $Z_{t-1},Z_{t-2}$를 곱하고 평균을 취하면 
\begin{align}
\gamma_1=\phi_1 \gamma_0+\phi_2 \gamma_1 \\\\ \\
\gamma_2=\phi_1 \gamma_1+\phi_2 \gamma_0
\end{align}
와 같이된다. 

- 따라서 
\begin{align}
\rho_1=\phi_1 +\phi_2 \rho_1 \\\\ \\
\rho_2=\phi_1 \rho_1+\phi_2 
\end{align}
와 같이된다. 

- 이제 PACF를 구해보자. 
\begin{align}
\phi_{11}=\rho_1=\frac{\phi_1}{1-\phi_2}
\end{align}

\begin{align}
\phi_{22}=\frac{\begin{vmatrix}  \rho_0 & \rho_1 \\\\ \\ \rho_1 & \rho_2  \end{vmatrix}}{\begin{vmatrix}  \rho_0 & \rho_1 \\\\ \\ \rho_1 & \rho_0  \end{vmatrix}}=\frac{\rho_2-\rho_1^2}{1-\rho_1^2}=\phi_2
\end{align}

\begin{align}
\phi_{33}=\frac{\begin{vmatrix}  \rho_0 & \rho_1 & \rho_1 \\\\ \\ \rho_1 & \rho_0 & \rho_1 \\\\ \\ \rho_2 &\rho_1 &\rho_3 \end{vmatrix}}{\begin{vmatrix}  \rho_0 & \rho_1 & \rho_2 \\\\ \\ \rho_1 & \rho_0 & \rho_1 \\\\ \\ \rho_2 &\rho_1 &\rho_0 \end{vmatrix}} = 0
\end{align}