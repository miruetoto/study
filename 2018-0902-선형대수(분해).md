---
layout: post 
title: (정리) 선형대수학 - 분해
---

### About this post

- 통계공부

- 학부수준 

- 이번에는 행렬의 분해를 다루겠다. 

- 본 포스트를 만들때 참고한 문헌은 아래와 같다. <br/>
Petersen, K. B., & Pedersen, M. S. (2008). The matrix cookbook. Technical University of Denmark, 7(15), 510. <br/>
Strang, G. (2006). Linear Algebra and Its Applications. Thomson, Brooks/Cole 


### Eigenvalues and Eigenvectors.  
- 임의의 정사각행렬 ${\bf A}_ {n \times n}$에 대하여 어떠한 벡터 ${\boldsymbol \psi}_ {n \times 1} \neq {\bf 0}$가 적당한값 $\lambda$에 대하여 아래식을 만족하면 $\boldsymbol v$를 $\bf A$의 고유벡터라고 한다. 
\begin{align}
{\bf A}{\boldsymbol \psi}= \lambda {\boldsymbol \psi}
\end{align}
주의할것은 $0$-벡터는 고유벡터로 취급하지 않는다는 것이다. 

- **고유값이 없는 정사각행렬은 없다.**
고유값이 없다는 말은 $det({\bf A}-\lambda {\bf I})=0$을 만족하는 $\lambda$가 없다는 말인데 임의의 $n$차 다항식의 해는 항상 존재하므로(정확하게는 모르겠지만 왠지 이런 정리가 있을것 같다) 어떠한 정사각행렬 ${\bf A}_ {n \times n}$도 $n$개의 고유값을 가진다. 다만 중복근이 존재할 수 있으므로 ${\bf A}_ {n \times n}$가 서로 다른 $n$개의 고유값을 가질 필요는 없다. 

- **하나의 고유값에 대응하는 고유벡터가 반드시 하나는 존재한다.**
일단 ${\bf A}_ {n \times n}$는 항상 $n$개의 고유값을 가진다. 그중에서 하나의 고유값 $\lambda^* $를 fix했다고 하자. 고유벡터가 없다는 말은 
\begin{align}
\left({\bf A}-\lambda^* {\bf I}\right){\boldsymbol \psi}={\boldsymbol 0}
\end{align}
를 만족하는 벡터 $\boldsymbol \psi$는 오직 ${\boldsymbol \psi}={\boldsymbol 0}$인 경우일 때 뿐이란 것을 의미한다. 그런데 고유값의 정의상 $det({\bf A}-\lambda^* {\bf I})=0$이 된다. 따라서 행렬 ${\bf A}-\lambda^* {\bf I}$은 *sing*-매트릭스가 된다. 따라서 ${\bf A}-\lambda^* {\bf I}$의 rows는 일차독립이 아니다. 따라서  $({\bf A}-\lambda^* {\bf I}){\boldsymbol \psi}={\boldsymbol 0}$을 만족하는 ${\boldsymbol \psi} \neq {\boldsymbol 0}$ 인 벡터가 적어도 하나는 존재한다. 

- 따라서 모든 정사각행렬은 고유벡터와 고유값을 반드시 가진다. 또한 하나의 고유값에 대응하는 고유벡터가 반드시 하나는 있다. 하지만 하나의 고유값에 반드시 하나의 고유벡터만 대응되는 것은 아니다. 예를들어서 $\bf A=I$일 경우와 $\bf A=O$일 경우가 그렇다. $\bf A=I$의 고유값은 $1$이고 고유벡터는 ***all non-zero vectors***다. 그리고 $\bf A=O$의 고유값은 $0$인데 고유벡터는 역시 ***all non-zero vectors***다. 이러한 사실들이 말해주는 것은 하나의 고유치에 대응하는 고유벡터가 무한개일 수도 있다는 것이다. 

- ${\bf A}_ {n \times n}$의 서로 다른 고유값에 대응하는 고유벡터는 선형적으로 독립이다. 요건 서로 다른 고유값 2개를 잡고 귀류법을 쓰면 엄청 쉽게 증명할 수 있다. 

- 지금까지 정리한 사항을 잘 추론하면 아래와 같은 사실들을 정리할 수 있다. 아래 사실들 중 당연하게 느껴지지 않는 사실들은 자주 읽으면서 외우는것이 좋다. <br/><br/>
**(1)** $n \times n$-행렬은 반드시 $n$개의 고유값을 가진다. <br/>
**(2)** 이 고유값들이 중복근일 경우가 있으므로 **서로 다른** $n$개의 고유값을 가질 필요는 없다. <br/>
**(3)** 한개의 고유값에는 반드시 한개 이상의 고유벡터가 대응한다. (특정한 고유치를 고정하면 그에 대응하는 고유벡터는 항상 존재해야 하므로) <br/>
**(4)** 하지만 한개의 고유치에 반드시 한개의 고유벡터**만** 대응할 필요는 없다. 때에 따라서 한개의 고유치에 여러개의 고유벡터가 대응할수도 있다. <br/>
위의 사실들을 잘 조합해보면 $n \times n$-행렬의 아이겐벡터가 *span*하는 차원이 $n$보다 작을경우는 **1)** 고유값들이 중복근을 가지며 (즉 (2)의 케이스) **2)** 그 중복근에 대응하는 고유벡터들이 *span*하는 공간의 차원이 중복근의 수보다 작은 경우이다. **그리고 바로 이 경우가 ${\bf A}_ {n \times n}$을 대각화할 수 없는 경우에 해당한다.** 
  
- ${\bf A}_ {n\times n}$이 대각화가능할 필요충분조건은 $\bf A$의 고유벡터들이 *span*하는 공간이 $n$차원일 경우이다. **가끔 가다가 ${\bf A}_ {n\times n}$이 대각화가능할 필요충분조건이 $\bf A$의 랭크가 $n$이라고 착각하는 사람들이 있는데 이것은 사실이 아니다.** $\bf A$의 랭크가 $n$이 아니어도 대각화 가능한 행렬은 얼마든지 있다. 바로 위에서 예를 든것처럼 ${\bf A}=0$도 대각화 가능하고 ${\bf A}=rbind(c(1,2),c(2,4))$와 같은 행렬도 (*real-symm*-매트릭스이므로) 대각화 가능하다. 

- **모든 *Hermitian*-매트릭스는 (1) 실수의 고유값을 가지며 (2) 아이겐벡터들이 서로 직교한다.** 행렬 $\bf A$의 성분들이 모두 실수이면 *symm*-매트릭스가 곧 *에르미트*-매트릭스가 된다. 따라서 **"모든 *real-symm*-매트릭스는 (1) 실수의 고유값을 가지며 (2) 고유벡터들이 서로 직교한다."** 라고 생각할 수 있다. 

- *real-symm*-매트릭스 ${\bf A}_ {n \times n}$는 아래와 같이 표현할 수 있다. 특별히 수학적인 의미가 있는건 아니고 단순히 전개한것 뿐이지만 매트릭스 표현법에 익숙해지기 위해서 한번 읽어보자. 
\begin{align}
{\bf A} & cbind({\boldsymbol \psi}_ 1, \dots, {\boldsymbol \psi}_ n)=cbind({\bf A}{\boldsymbol \psi}_ 1, \dots, {\bf A}{\boldsymbol \psi}_ n)=cbind(\lambda_1 {\boldsymbol \psi}_ 1, \dots, \lambda_n {\boldsymbol \psi}_ n) \\\\ 
&=cbind(P_1, \dots, P_n)diag(\lambda_1,\dots,\lambda_n)
\end{align}
따라서 *real-symm*-매트릭스 ${\bf A}_ {n \times n}$는 아래와 같이 표현 가능하다. 
\begin{align}
{\bf A}{\boldsymbol \Psi}={\boldsymbol \Psi}{\bf \Lambda} ~~ or ~~ {\bf A}={\boldsymbol \Psi}{\bf \Lambda}{\boldsymbol \Psi}'
\end{align}
여기에서 ${\boldsymbol \Psi}=[{\boldsymbol \psi}_ 1 ,\dots,{\boldsymbol \psi}_ n]$이고 ${\bf \Lambda}=diag(\lambda_1,\dots,\lambda_n)$이다. 그리고 ${\bf A}={\boldsymbol \Psi}{\bf \Lambda}{\boldsymbol \Psi}'$를 그대로 풀면 아래와 같이 쓸 수 있다. 
\begin{align}
{\bf A}&=[{\boldsymbol \psi}_ 1 ,\dots,{\boldsymbol \psi}_ n] diag(\lambda_1, \dots, \lambda_n) rbind({\boldsymbol \psi}_ 1', \dots, {\boldsymbol \psi}_ n') \\\\ \\\\
&=[{\boldsymbol \psi}_ 1\lambda_1 ,\dots,{\boldsymbol \psi}_ n\lambda_n] rbind({\boldsymbol \psi}_ 1', \dots, {\boldsymbol \psi}_ n') \\\\ \\
&=\sum_{i=1}^{n} \lambda_i {\boldsymbol \psi}_ i {\boldsymbol \psi}_ i'
\end{align}
특히 
\begin{align}
{\bf A}={\boldsymbol \Psi}{\bf \Lambda}{\boldsymbol \Psi}'=\sum_{i=1}^{n} {\boldsymbol \psi}_ i \lambda_i {\boldsymbol \psi}_ i'
\end{align}
와 같은 표현이나 
\begin{align}
{\bf A}{\boldsymbol \Psi}={\boldsymbol \Psi}{\bf \Lambda}
\end{align}
와 같은 표현은 자주 나오므로 익숙해지는 것이 좋다. 

- *에르미트*-매트릭스 ${\bf A}_ {n \times n}$의 모든 고유값이 양수일때 이러한 행렬 $\bf A$를 *(에르미트)-pd*-매트릭스라고 부른다. *pd*-매트릭스는 기본적으로 *에르미트*-매트릭스이어야 하므로 이를 앞으로 *(에르미트)-pd*-매트릭스라 표현하겠다. *(에르미트)-pd*-매트릭스는 말그대로 1) 에르미트행렬이며 2) 모든 고유치가 양수라는 조건을 만족해야하는데 이러한 2가지 조건이 만족되면 모든 *non-zero vector* ${\boldsymbol y}$에 대하여 아래식을 만족한다. 
\begin{align}
{\boldsymbol y}^{H}{\bf A}{\boldsymbol y}>0
\end{align}
이는 ${\bf A}={\boldsymbol \Psi}{\boldsymbol \Lambda}{\boldsymbol \Psi}^H$꼴로 변형하고 위의 식의 대입하면 쉽게 증명할 수 있다. 반대로 어떠한 정사각행렬 ${\bf A}$가 모든 *non-zero vector* ${\boldsymbol y}$에 대하여 위의 식을 만족하면 이 행렬 ${\bf A}$는 (1) *에르미트*-매트릭스이며 (2) 모든 고유치가 양수인 행렬이 된다(이것도 쉽게 증명된다). 즉 아래조건은 *(에르미트)-pd*-매트릭스의 정의처럼 사용가능하다. 
\begin{align}
\forall {\boldsymbol y}\neq {\boldsymbol 0}: ~~ {\boldsymbol y}^{H}{\bf A}{\boldsymbol y}>0
\end{align}

--- 
***Eigenvalue, Eigenvector에 대한 미세먼지 팁***
- **모든 고유값들의 합은 원래 행렬의 trace와 같고 모든 고유값들의 곱은 원래 행렬의 determinent와 같다. 이 사실은 임의의 정사각행렬에서 성립한다.** 즉 임의의 정사각행렬에서 $tr({\bf A}_ {n \times n})=\sum_{i=1}^{n} \lambda_i$이고 $det({\bf A}_ {n \times n})=\prod_{i=1}^{n}\lambda_i$이다. 이 사실은 그냥 증명없이 외우자. 

- ***sing*-매트릭스의 고유값에는 0이 적어도 하나는 포함되어 있다.** 이 사실은 **모든 고유값들의 곱은 원래 행렬의 determinent와 같다**는 사실을 떠올리면 쉽게 이해할 수 있다. 

- $A_{n \times n}$모든 col의 합이 1인 행렬을 *markov*-매트릭스라고 한다. **markov-매트릭스의 고유값들중 최소한 하나는 1이고 나머지 고유값은 모두 1보다 작다.** 이 사실은 그냥 증명없이 외우자. 

- **임의의 $2\times 2$-행렬 ${\bf A}=rbind(c(a,b),c(c,d))$에서 고정된 고유값 $\lambda^* $에 대한 고유벡터는 $c(-b,a-\lambda^ * )$이다.** 이건 그냥 혼자 유추한것인데 상당히 유용하다. 증명은 그렇게 어렵지 않다. 우선 임의의 $2 \times 2$-행렬의 고유값과 고유벡터는 항상 존재한다. 고정된 고유값 $\lambda^* $에 대한 *characteristic polynomial*은 아래와 같이 쓸 수 있다. 
\begin{align}
det\left({\bf A}-\lambda^* {\bf I}\right)=0
\end{align}
앞에서 언급하였듯이 고유치 $\lambda^* $의 정의에 의해서 위의 식은 항상 성립한다. 따라서 행렬 ${\bf A}-\lambda^* {\bf I}$는 *sing*-매트릭스이다. 따라서 0을 고유값으로 가지며 0에 해당하는 고유벡터는 ${\boldsymbol \psi}=(-b,a-\lambda^* )$이다. 그런데 ${\boldsymbol \psi}$는 행렬 ${\bf A}-\lambda^* {\bf I}$에서 고유값 0에 대한 고유벡터이기도 하지만 행렬 ${\bf A}$에서 고유값 $\lambda^* $에 대한 고유벡터이기도 하다. 왜냐하면 
\begin{align}
\left({\bf A}-\lambda^* {\bf I}\right){\boldsymbol \psi}=0
\end{align}
이므로, 
\begin{align}
{\bf A}{\boldsymbol \psi}=\lambda^* {\boldsymbol \psi}
\end{align}
이기 때문이다. 

- 매트릭스 ${\bf A}=rbind(c(0.5,0.5),c(0.5,0.5))$를 생각하여 보자. $\bf A$는 *sing*-매트릭스이므로 0을 고유값으로 가진다. 또한 $\bf A$는 *markov*-매트릭스 이므로 1을 고유값으로 가진다(그리고 다른 고유값은 모두 1보다 작음). 종합하면 $\bf A$의 고유값은 0과 1이다. 따라서 고유벡터는 $c(-0.5,0.5)$, $c(-0.5,-0.5)$이다. 

- **모든 고유값들의 합은 원래 행렬의 trace와 같고 모든 고유값들의 곱은 원래 행렬의 determinent와 같다.** 이 2개의 사실을 연립하여 풀면 모든 $2 \times 2$-매트릭스의 고유값을 쉽게 구할 수 있다. 가령 예를 들면 ${\bf A}=rbind(c(1,2),c(2,4))$인 행렬을 생각하자. $\lambda_1+\lambda_2=5$ 이고 $\lambda_1 \lambda_2=0$ 이다. 따라서 고유값은 0과 5임을 쉽게 유추할 수 있다. 그리고 고유값만 알면 고유벡터는 $c(-b,\lambda-a)$로 바로 찾아질 수 있다. 예를 들어서 이 행렬에서 $0$에 대응하는 고유벡터는 $c(-2,1)$이고 $5$에 대응하는 고유벡터는 $c(-2,-4)$이다. 

- 임의의 정사각행렬 ${\bf A}$의 값이 모두 실수여도 그 고유값이 반드시 실수인것은 아니다. ${\bf A}=rbind(c(0,-1),c(1,0))$을 생각하여 보자. $\lambda_1+\lambda_2=0$ 이고 $\lambda_1 \lambda_2=1$이다. $i$와 $-i$가 해당조건을 만족하므로 ${\bf A}$의 고유값은 $i$와 $-i$이다. 이때 고유값 $i$에 대응하는 고유벡터는 $c(1,-i)$이고 고유값 $-i$에 대응하는 고유벡터는 $c(1,i)$이다. 

- ${\bf A}$가 *orthogonal*-매트릭스이면 모든 고유값들의 절대값이 1이다. 즉 $\|\lambda\|=1$이다. 이것은 귀류법을 쓰면 쉽게 증명가능하다.

--- 

### Singular value decomposition
 
- SVD는 아래와 같이 정의하는 것이 편리하다. 
\begin{align}
{\bf X}_ {n\times p}={\bf U}_ {n\times n} {\bf D}_ {n \times p} {\bf V}_ {p\times p}'
\end{align}
**따라서 ${\bf D}$는 대각행렬이 아니다.** 이렇게 ${\bf D}$를 대각행렬로 정의안하면 아래가 성립한다. 
\begin{align}
\bf U'U=UU'=I
\end{align}
\begin{align}
\bf V'V=VV'=I
\end{align}
문헌에 따라서 $\bf D$를 대각행렬로 정의하는 버전도 있는데 이는 그냥 무시하자. 이런 버전으로 정리하면 위와 같이 $\bf U'U=UU'=I$ 와 $\bf V'V=VV'=I$ 가 동시에 성립하지는 않아서 다루기 까다롭다.  

- 만약에 행렬 ${\bf A}$가 ***psd-symm*** 인 경우 아래가 성립한다. 
\begin{align}
\bf A= UDV'=\Psi \Lambda \Psi'
\end{align}
즉 고유치분해와 SVD는 같다는 의미이다. 구체적으로는 아래가 성립한다. 
\begin{align}
{\bf U}=&{\bf V}={\bf U}'={\bf V}'={\boldsymbol \Psi}={\boldsymbol \Psi}' \\\\ 
{\bf D}=&{\boldsymbol \Lambda}
\end{align}
따라서 ${\bf A}$가 ***psd-symm*** 일 경우 한정으로 아래와 같이 R-code를 짜도 좋다. 
```r
svdrslt<-svd(A)
λ<-svdrslt$d
Λ<-diag(λ)
U<-svdrslt$u; 
V<-svdrslt$v; 
Ψ<-U
```
당연히 위와 같이 짠뒤에 U%*%D%*%t(V), 혹은 Ψ%*%Λ%*%t(Ψ) 를 실행하면 원래행렬이 만들어진다. 
```r
A == U%*%D%*%t(V)
A == Ψ%*%Λ%*%t(Ψ)
```
그리고 이 경우에 한정하여 아래가 성립한다. 
\begin{align}
{\bf U}^2={\bf V}^2={\boldsymbol \Psi}^2={\bf I}
\end{align}
참고로 여기에서 ${\bf U}$는 (1) 직교행렬 (2) 대칭행렬 (3) 제곱해서 ${\bf I}$가 되는 행렬이다. 이런 행렬이 없을것 같은데 분명히 있다. 아래와 같은 행렬을 생각해보자. 
\begin{align}
{\bf A}=\begin{pmatrix} 4 & 2 \\\\ 2 & 4 \end{pmatrix}
\end{align}
고유치를 풀기위해서는 아래를 연립하면 된다. 
\begin{align}
\lambda_1 +\lambda_2 = 8
\lambda_1 \lambda_2 = det({\bf A})=12 
\end{align}
따라서 고유치는 6과 2이다. $2\times 2$ 행렬에서 고유벡터는 $c(-b,a-\lambda)$이므로, 각각의 고유벡터는 아래와 같다. 
\begin{align}
\begin{pmatrix} -2 \\\\ 4-6 \end{pmatrix} \quad \begin{pmatrix} -2 \\\\ 4-2 \end{pmatrix}
\end{align}
따라서 이를 표준화하면 $\boldsymbol\Psi$는 아래와 같다. 
\begin{align}
{\boldsymbol \Psi} = \begin{pmatrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\\\ -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \end{pmatrix} 
\end{align}
이 행렬은 분명히 (1) 직교행렬이고 (2) 대칭행렬이고 (3) 제곱하면 ${\bf I}$이다. 

