---
title: (정리) 베이지안 
layout: post
---

### About this doc

- 통계공부 

- 학부수준 

- 이 문서에서는 베이지안 대하여 다룬다. 베이지안 추론법이 아니라 베이지안을 다룬다고 한 이유는 그들의 방법을 이해하기 위함이 아니라 그들의 철학 혹은 사고방식을 이해하기 위함이다. 

- 교재는 예전에 내가 공부했던 Hogg 5판, 그리고 김우철 수리통계학책.


### 사후분포를 구하는 두 가지 방법

- 가볍게 예제로 시작하자. $x_1,\dots,x_n$는 모수가 $\lambda$인 포아송분포에서 추출한 ***i.i.d.*** 샘플이라고 하자. (좀더 엄밀하게 쓰면 $X$는 모수가 $\lambda$인 포아송분포를 따르고 $x_1,\dots,x_n$ 은 $X$의 ***i.i.d. realization*** 이라고 말해야 한다.) 그리고 $\lambda$는 확률변수 $\Lambda$의 ***realization*** 이며 확률변수 $\Lambda$는 모수가 $\alpha$, $\beta$ 인 감마분포를 따른다고 하자. 이러한 상황을 보통 관용적으로는 간단하게 아래와 같이 표현한다. 
\begin{align}
\begin{cases}
\lambda \sim \Gamma(\alpha,\beta) \\\\ \\
x_1,\dots,x_n \sim ~ i.i.d.~ \mbox{Poission}(\lambda)
\end{cases}
\end{align}
그런데 좀 더 엄밀하게는(=좀 더 엄밀한 빈도주의적 관점에서는) 아래와 같이 표현하는것이 더 정확하다. 
\begin{align}
\begin{cases}
\Lambda \sim \Gamma(\alpha,\beta) \\\\ \\
X_1,\dots,X_n \| \lambda \sim ~ i.i.d.~ \mbox{Poission}(\lambda)
\end{cases}
\end{align}
사실 이처럼 $\lambda$와 $\Lambda$를 구분하면서 말하는게 더 엄밀하면서 이해도 쉬운데 그렇게 안하는 이유는 따로 있다. 그냥 노테이션상 그리스기호의 대문자로 쓸 수 있는게 한정적이기 때문이다. $\lambda$를 확률변수 $\Lambda$의 realization으로 이해하는것은 아무 무리가 없지만 $\sigma$를 $\Sigma$의 realization 으로 표기해야 한다든가, $\alpha$를 $A$의 realization 으로 표기해야하면 오히려 더 큰 혼란이 생긴다. 그래서 김우철 교수님의 수리통계학 p.459 에서는 "확률변수 $\Theta$와 취하는 값 $\theta$를 구별하지 않고 모두 $\theta$로 나타내기로 한다." 라는 문장이 있다. 

- 여기에서 많은 사람들이 헷갈려하는 점을 짚고 넘어가겠다. 혼돈은 $\lambda$를 파라메터로 부르는 것이 맞나? 라는 의문에서 시작된다. 이미 언급했지만  $\lambda$는 파라메터가 아니라 확률변수의 realization 을 의미하고 오히려 $\alpha,\beta$ 를 파라메터라고 부르는 것이 맞다고 생각한다. 하지만 이런 관점은 빈도주의적 관점이다. 베이지안들은 $\alpha,\beta$ 를 하이퍼파라메터라고 하고 $\lambda$를 그냥 파라메터라고 부른다. 그리고 베이지안들은 파라메터를 랜덤변수의 realization으로 생각한다. 정리하면 아래와 같다. 빈도주의자의 입장에서 정리하였다. (괄호는 베이지안들의 입장) 

  - $\alpha$, $\beta$ : parameter (hyper-parameter)
  - $\lambda$ : realization of $\Lambda$ (parameter)
  - $x_1,\dots,x_n$: ***(i.i.d.)*** realizations of $X$. 

 
- 아무튼 이러한 상황에서 우리가 구할것은 $f(\lambda \| x_1,\dots,x_n)$ 이다. 이를 $\lambda$ 의 사후분포라고 한다. 내친김에 관련된 용어들을 정리하여 보자.

  - $f(\lambda)$ : 사전분포, ***prior***.
  - $f(x_1,\dots,x_n\|\lambda)$ : 우도, ***likelihood***. 
  - $f(\lambda \| x_1,\dots,x_n)$ : 사후분포, ***posterior***.
  - $f(x_1,\dots,x_n,\lambda)$: 결합분포, ***joint***. 
  - $f(x_1,\dots,x_n)$: 주변분포, ***marginal***. 
  
- 여기에서 또 사소한 헷갈림이 발생한다. 일반적으로 빈도주의자들이 말하는 우도함수는 $L(\lambda)=f(x_1,\dots,x_n ; \lambda)$ 와 같이 표현한다. 이때 빈도주의자들은 $f(x_1,\dots,x_n ; \lambda)$ 대신에 간략하게 $f(x_1,\dots,x_n)$ 와 같이 쓰기도 하는데 이는 베이지안들이 생각하는 마지널의 표기법과 겹친다. 즉 
\begin{align}
f(x_1,\dots,x_n)
\end{align}
이 빈도주의자들에게는 우도함수로 보이고 베이지안에게는 마지날로 보인다. 베이지안들은 절대로 우도함수를 위와같이 쓰지 않는다. 철저하게 
\begin{align}
f(x_1,\dots,x_n \| \lambda)
\end{align}
와 같이 쓴다. 대신 빈도주의자들은 우도함수를 $f(x_1,\dots,x_n ; \lambda)$ 혹은 $L(\lambda)$ 혹은 $f(x_1,\dots,x_n)$ 와 같이 쓴다. 

- 다시 우리의 문제로 돌아와서 사후분포 즉 $f(\lambda \| x_1,\dots,x_n)$ 을 구하는 방법에 대하여 알아보자. 

- **(풀이 1: 미련함)** 정석적인 풀이를 해보자. 아마 좀 어려울거다. 조건부 ***pdf*** 의 정의에 의해서 아래식이 성립한다. 
\begin{align}
f(\lambda \| x_1,\dots,x_n) = \frac{f(x_1,\dots,x_n,\lambda)}{f(x_1,\dots,x_n)}
\end{align}
따라서 위를 계산하려면 $f(x_1,\dots,x_n,\lambda)$ 와 $f(x_1,\dots,x_n)$ 를 각각 계산하면 된다. 여기에서 $f(x_1,\dots,x_n,\lambda)$는 아래와 같이 쓸 수 있다. 
\begin{align}
f(x_1,\dots,x_n,\lambda)= \left( \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda} }{x_i !} \right) \frac{\lambda^{\alpha-1}e^{-\lambda/\beta} }{\Gamma(\alpha)\beta^{\alpha} }
\end{align}
이제 $f(x_1,\dots,x_n)$을 계산하면 되는데 이는 $f(x_1,\dots,x_n,\lambda)$을 적분해서 얻을 수 있다. 즉
\begin{align}
f(x_1,\dots,x_n)=\int f(x_1,\dots,x_n,\lambda) d\lambda 
\end{align}
을 계산하면 된다. 적분을 항상 손으로 계산할 수 있을지는 모르지만 위의 경우는 계산할 수 있다. 아무튼 계산해보면 아래와 같다. (이번 한번만 계산할것이다) 
\begin{align}
f(x_1,\dots,x_n)&=\int f(x_1,\dots,x_n,\lambda) d\lambda  \\\\ \\
&= \int_0^{\infty} \left( \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda} }{x_i !} \right) \frac{\lambda^{\alpha-1}e^{-\lambda/\beta} }{\Gamma(\alpha)\beta^{\alpha} } d\lambda \\\\ \\
&= \frac{1}{\prod x_i! \Gamma(\alpha) \beta^{\alpha} } \int_0^{\infty}\lambda^{\sum x_i + \alpha-1 } e^{-\lambda \big(n+\frac{1}{\beta}\big)} d\lambda
\end{align}
감마함수의 정의에 따라서 아래식이 성립한다. 
\begin{align}
\Gamma(n):=\int_{0}^{\infty} y^{n-1} e^{-y} dy 
\end{align}
요걸 이용하면 아래를 얻을 수 있다. (A4 용지 반페이지 정도 투자해서 치환적분해보면 풀린다) 
\begin{align}
f(x_1,\dots,x_n)
=\frac{\Gamma(\sum x_i+\alpha)}{x_1! \dots x_n! \Gamma(\alpha) \beta^{\alpha} \big(n+\frac{1}{\beta}\big)^{\sum x_i+\alpha} }
\end{align}
여기까지 결과를 정리하면 아래와 같다. 
\begin{align}
\begin{cases}
f(x_1,\dots,x_n,\lambda)= \left( \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda} }{x_i !} \right) \frac{\lambda^{\alpha-1}e^{-\lambda/\beta} }{\Gamma(\alpha)\beta^{\alpha} } \\\\ \\
f(x_1,\dots,x_n)
=\frac{\Gamma(\sum x_i+\alpha)}{\prod x_i! \Gamma(\alpha) \beta^{\alpha} \big(n+\frac{1}{\beta}\big)^{\sum x_i+\alpha} }
\end{cases}
\end{align}
이제 (드디어) 아래식만 계산하면 풀이가 끝난다. 
\begin{align}
f(\lambda \| x_1,\dots,x_n) = \frac{f(x_1,\dots,x_n,\lambda)}{f(x_1,\dots,x_n)}
\end{align}
계산해보면 아래와 같이 정리된다. 
\begin{align}
f(\lambda \| x_1,\dots,x_n)=\frac{\lambda^{\sum x_i \alpha-1} e^{-\lambda\big(n+\frac{1}{\beta}\big)} }{\Gamma(\sum x_i+\alpha)\big(n+\frac{1}{\beta} \big)^{- \sum x_i - \alpha} }
\end{align}
따라서 $\lambda$의 사후분포는 모수가 $\big(\sum x_i+\alpha,\big(n+\frac{1}{\beta}\big)^{-1} \big) $ 인 감마분포를 따른다. 

- **(풀이 2: 똑똑함)** : 좀 더 쉽게 푸는 방법을 알려주겠다. 이는 아래와 같은 **베이즈정리**를 이용하는 것이다. 
\begin{align}
f(\lambda | x_1,\dots,x_n) \propto f(x_1,\dots,x_n | \lambda) f(\lambda) 
\end{align}
위의 식을 아래와 같이 외우는 사람도 있다. 
\begin{align}
\mbox{ posterior } \propto \mbox{ likelihood } \times \mbox{ prior } 
\end{align}
뭐 저렇게만 보면 $\mbox{likelihood} \times \mbox{prior}$ 가 엄청난 의미를 가지고 있는것 같은데 그냥 $({\boldsymbol x},\theta)$의 ***joint pdf*** 란 의미다. 여기에서 ${\boldsymbol x}=(x_1,\dot,x_n)'$ 이다. 
참고로 위에서 $\propto$ 의 의미는 잘 아는것처럼 **비례**라는 의미이다. 즉 $f(y) \propto g(y)$ 라는 의미는 적당한 상수 $k$ 가 존재하여 $f(y)=k \times g(y)$ 가 성립한다는 의미이다. 이때 $k$는 진짜 $0.2$ 같은 상수란 의미가 아니라 $y$와 상관없는 어떤 수식이라는 의미이다. 베이즈정리의 증명은 그렇게 어렵지 않다. 
\begin{align}
f(\lambda | x_1,\dots,x_n) =& \frac{f(\lambda,x_1,\dots,x_n)}{f(x_1,\dots,x_n)} 
= \frac{f(\lambda)f(x_1,\dots,x_n | \lambda)}{f(x_1,\dots,x_n)} \\\\ \\
=& \mbox{const with regard to $\lambda$} \times f(x_1,\dots,x_n | \lambda) f(\lambda) 
\end{align}
결국 아래를 위우면 된다. 
\begin{align}
\mbox{ posterior } =& \mbox{ inverse of marginal } \times \mbox{ joint } \\\\ \\
=& \mbox{ inverse of marginal } \times \mbox{ likelihood } \times \mbox{ prior } \\\\ \\
\propto& \mbox{ likelihood } \times \mbox{ prior }
\end{align}
베이즈정리를 잘 생각해보면 사후분포는 다음의 과정으로 구할 수 있음을 알 수 있다. **(1)** join를($=\mbox{likelihood} \times \mbox{prior}$)를 쓰고 **(2)** $\{x_1,\dots,x_n\}$ 와 하이퍼파라메터에 관련된텀은 모두 무시하고 $\lambda$와 관련된텀만 남겨 간추린모양을 만든 뒤 **(3)** 간추린모양을 보고 ***pdf*** 를 역추론해 때려맞춘다. 위의 예제로 치면 아래와 같이 joint를 쓴뒤 
\begin{align}
f(x_1,\dots,x_n,\lambda)= \left( \prod_{i=1}^{n} \frac{\lambda^{x_i} e^{-\lambda} }{x_i !} \right) \frac{\lambda^{\alpha-1}e^{-\lambda/\beta} }{\Gamma(\alpha)\beta^{\alpha} }
\end{align}
정리해서 아래와 같이 **간추린모양** 를 만든다. 
\begin{align}
f(x_1,\dots,x_n,\lambda) \propto \lambda^{\sum x_i+\alpha -1} e^{-\lambda\big(n+\frac{1}{\beta}\big)}
\end{align}
이는 모수가 $\big(\sum x_i+\alpha,\big(n+\frac{1}{\beta}\big)^{-1} \big) $  인 감마분포의 **간추린모양**이다. 따라서 사후분포는 모수가 $\big(\sum x_i+\alpha,\big(n+\frac{1}{\beta}\big)^{-1} \big) $ 인 감마분포이다. 


- **(풀이 3: 더 똑똑한 풀이)** : 그냥  켤레 외우는 사람이 젤 똑똑한 사람이다. 켤레는 맨 마지막에 정리해두었다. 


### Bayes estimator

- 여기서는 베이즈추정량에 대하여 다룬다. 이를 정의하기 위해서 ***loss, MSE, risk, Bayes risk*** 와 같은 용어들이 나온다. 참고로 이 챕터는 엄청 헷갈린다. 거의 책마다 정의하는게 다른 느낌이다. 하지만 여기저기 뒤적거리면서 내 나름대로 정리했다. 우선 가장 헷갈리는 MSE부터 정리하자. 

- MSE는 크게 2가지 부류로 나뉜다. (https://en.wikipedia.org/wiki/Mean_squared_error)
\begin{align}
\begin{cases}
\mbox{MSE}:=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_ i)^2 \\\\ \\
\mbox{MSE}:=\mathbb{E}(\lambda-\hat\lambda)^2
\end{cases}
\end{align}
위의식은 predictor에 대한 MSE의 정의이고 아래식은 estimator에 대한 MSE의 정의이다. 다소 헷갈리지만 그냥 **회귀식정의**와 **수통식정의** 2개 있다고 생각하는 것이 속 편하다.  

- 회귀식 MSE는 잔차제곱 즉 $e_i^2=(y_i-\hat{y}_ i)^2$의 average이다. 수통식 MSE는 손실함수 $(\lambda-\hat{\lambda})^2$ 의 mean이다. 여기에서 미치겠는것은 머신러닝쪽에서는 회귀식 MSE 그 자체를 손실함수라고 표현하기도 한다는 점이다. (요건 최적화쪽에서 따온 용어인데 최적화하는 사람들은 objective function 을 그냥 손실함수라고 부른다) 우선 여기서는 이런 용어는 무시하자. 그리고 우리는 수통식으로 정의한 MSE에만 관심을 가지자. 

- 황당한 점은 또 빈도주의자와 베이지안이 생각하는 수통식 MSE의 정의가 다르다는 것이다. 이런일이 생기는 근본적인 이유는 베이지안들은 $\lambda$를 랜덤변수 $\Lambda$의 realization으로 보기 때문이다. 빈도주의자는 손실함수를 우도함수로 적분하고(**expectation is taken over the likelihood of $x_1,\dots,x_n$**) 베이지안들은 손실함수를 조인트로 적분한다(**expectation is taken over the joint distribution of $x_1,\dots,x_n$ and $\lambda$**). 즉 빈도주의자들은 MSE를 아래와 같이 정의한다. 이를 간단히 빈도주의식 MSE라고 하자. 
\begin{align}
\mathbb{E}(\lambda-\hat\lambda)^2:=\int \dots \int (\lambda-\hat{\lambda})^2 f(x_1,\dots,x_n ; \lambda) dx_1\dots dx_n 
\end{align}
반면에 베이지안은 MSE를 아래와 같이 생각한다. 이를 간단히 베이지안식 MSE라고 하자. 
\begin{align}
\mathbb{E}(\lambda-\hat\lambda)^2:=\int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda
\end{align}
이러한 정의는 아래를 참고하면 나온다. <br/><br/>
  - https://en.wikipedia.org/wiki/Loss_function#Expected_loss 
  - https://en.wikipedia.org/wiki/Bayes_estimator#cite_note-1 <br/>
 
- 그리고 베이지안들은 베이지안식 MSE을 최소화하는 $\hat\lambda$를 베이즈룰이라고 정의한다. 즉 아래가 성립한다. 
\begin{align}
\mbox{Bayes rule}:=\underset{\lambda}{\operatorname{argmin} } \int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda
\end{align}
이걸 계산하기 위해서는 아래를 계산하면 된다. 
\begin{align}
\frac{\partial}{\partial \lambda} \int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda
\end{align}
그런데 위의 식은 아래와 같이 풀 수 있다. 
\begin{align}
\frac{\partial}{\partial \lambda}
\int & \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda \\\\ \\
&= \frac{\partial}{\partial \lambda} \int \dots \int \Bigg\\{ \int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda \Bigg\\}f(x_1,\dots,x_n) dx_1\dots dx_n \\\\ \\
&= \int \dots \int \Bigg\\{\frac{\partial}{\partial \lambda} \int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda \Bigg\\}f(x_1,\dots,x_n) dx_1\dots dx_n
\end{align}
따라서 결국 아래의 두 최적화 문제는 같은 문제이다. 
\begin{align}
\begin{cases}
\underset{\lambda}{\operatorname{argmin} }  \int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda \\\\ \\
\underset{\lambda}{\operatorname{argmin} } \int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda
\end{cases}
\end{align}

- 잠시 애매한 용어를 정리하고 넘어가겠다. 빈도주의자와 베이지안 모두 추정량은 MSE(=expectation of loss=risk)를 최소화하면 된다는 마인드를 가지고 있다. 그런데 빈도주의자의 관점에서는 
\begin{align}
\mbox{MSE}=\mbox{risk}=\mbox{expectation of loss}=\int \dots \int (\lambda-\hat{\lambda})^2 f(x_1,\dots,x_n ; \lambda) dx_1\dots dx_n 
\end{align}
와 같이 정의된다. 베이지안의 경우는 아래와 같이 정의된다. 
\begin{align}
\mbox{MSE}=\mbox{risk}=\mbox{expectation of loss}=\int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda
\end{align}
그런데 요 MSE가 빈도주의자들에게는 아래와 같은 식으로 보일수도 있다. 
\begin{align}
\int & \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda \\\\ \\
&=\int \Bigg\\{ \int \dots \int (\lambda-\hat{\lambda})^2 f(x_1,\dots,x_n \| \lambda) dx_1\dots dx_n \Bigg\\}f(\lambda)d\lambda \\\\ \\
&=\int \Big\\{\mbox{ risk function defined by frequentist } \Big\\} f(\lambda)d\lambda
\end{align}
즉 베이지안식 MSE는 빈도주의주의식 MSE를 프라이어로 적분한것으로 볼 수 있다. 다시 말하면 베이지안식 risk는 빈도주의식 risk를 프라이어로 적분한 것이라 볼 수 있다. 그래서 빈도주의자들이 쓴 베이지안챕터는 베이지안식 MSE 혹은 베이지안식 risk를 ***mean of risk*** 라는 다소 해괴한 표현을 쓴다. 물론 베이지안 입장에서는 베이지안식 MSE는 그냥 깔끔하게 ***expected loss, risk, MSE*** 이다. 

- 그런데 애매한점은 여기에서 그치지 않는다. 아래의 최소화문제
\begin{align}
\begin{cases}
\underset{\lambda}{\operatorname{argmin} }  \int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda \\\\ \\
\underset{\lambda}{\operatorname{argmin} } \int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda
\end{cases}
\end{align}
가 똑같기 때문에 
\begin{align}
\int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda
\end{align}
자체를 그냥 ***risk*** 로 생각하자는 베이지안도 있다. 즉 이러한 베이지안은 위의식 자체가 그냥 
***expected loss, risk, MSE*** 라는 마인드이다. (https://en.wikipedia.org/wiki/Loss_function#Expected_loss) 

- 그런데 위와 같은 정의는 왜 이런식으로 정의했는지 이해는 되지만 쓰기에는 너무 헷갈린다(빈도주의자들의 용어와 충돌함). 그래서
\begin{align}
\int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda
\end{align}
는 ***Bayes risk*** 로 부르고 
\begin{align}
\int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1 \dots dx_n d\lambda
\end{align}
는 따로 별다른 명칭을 정의하지 않는 사람들이 대다수이다. 왜냐하면 
\begin{align}
\int \int \dots \int (\lambda-\hat{\lambda})^2 f(\lambda,x_1,\dots,x_n) dx_1\dots dx_n d\lambda
\end{align}
을 ***expected loss, risk, MSE*** 등으로 정의하자니 빈도주의자의 반발이 거세다. 그렇다고 하여 ***mean of risk*** 라고 보기에는 베이지안들의 반발이 거세다. 이처럼 많은 논쟁이 되는 식인데 위의 식은 결정적으로 필요가 없다. 빈도주의자들은 애초에 없는 식이었고 베이지안들은 어차피 위의 식을 최소화하는 것이 아닌 ***Bayes risk*** 를 최소화하면 그만이기 때문에 필요가 없다. 베이지안 입장에서는 필요도 없는 식의 명칭때문에 싸울 이유가 없다. 그래서 요즘은 그냥 ***Bayes risk, Bayes rule*** 만 정의하면서 얼렁뚱땅 넘어가는 주의이다. 

- 이제 다시 원래의 문제로 돌아와서 베이즈룰을 구하기 위해서 아래를 푸는 방법을 고민해보자. 
\begin{align}
\frac{\partial}{\partial \lambda} \int (\lambda-\hat{\lambda})^2 f(\lambda\|x_1,\dots,x_n) d\lambda =0 
\end{align}
미분과 적분의 순서를 바꿔서 계산하면 베이즈룰이 ***mean of posterior*** 임을 너무 쉽게 구할 수 있다. 즉 
\begin{align}
\mbox{Bayes rule}:= \int \lambda f(\lambda \| x_1,\dots,x_n)d\lambda
\end{align}
이다. 

---

***Conjugate Prior*** 

| likelihood | prior | posterior  |
|:-----------|:------|:-----------|
|$X_1,\dots,X_n \|\lambda \sim \mbox{Poisson}(\lambda)$ | $\Lambda \sim \Gamma(\alpha,\beta)$ | $\Lambda\| x_1,\dots,x_n \sim \Gamma\big(\sum x_i+\alpha,\big(n+\frac{1}{\beta}\big)^{-1} \big)$ |
|$X_1,\dots,X_n \|p \sim \mbox{Bernoulli}(p)$ | $p \sim \mbox{Beta}(\alpha,\beta)$ | $p \|x_1,\dots,x_n \sim \mbox{Beta}\big(\sum x_i + \alpha, n-\sum x_i + \beta)$
|$X_1,\dots,X_n \|\frac{1}{\mu} \sim \mbox{Exp}(\frac{1}{\mu})$ | $\frac{1}{\mu} \sim \Gamma(\alpha,\beta)$ | $\frac{1}{\mu} \| x_1,\dots,x_n \sim \Gamma\big(n+\alpha,\big(\sum x_i+\frac{1}{\beta}\big)^{-1} \big)$ 
|$X_1,\dots,X_n \| \mu, \sigma^2  \sim N(\mu,\sigma^2)$     |      $\frac{\nu V(\mu\|\sigma^2)}{\sigma^2} \sim  \chi^2(\nu)$ <br/> $\mu \| \sigma^2 \sim N \big(E(\mu\|\sigma^2), V(\mu\|\sigma^2)\big)$     |     $\frac{\nu V(\mu\|\sigma^2)+(n-1)s^2}{\sigma^2}  + \frac{(n^{-1}+\kappa^{-1})^{-1}(\bar{x}+E(\mu\|\sigma^2))^2}{\sigma^2} \big\|x_1,\dots,x_n \sim  \chi^2(n+\nu)$ <br/> $\mu \| \sigma^2, x_1,\dots,x_n \sim N\Big(\frac{n\bar{x} +\kappa E(\mu\|\sigma^2)}{n+\kappa} , \frac{\sigma^2}{n+\kappa}\Big)$, where $\kappa:=\frac{\sigma^2}{V(\mu\|\sigma^2)}$. <br/> $\frac{\frac{\mu-E(\mu\|\sigma^2,x_1,\dots,x_n)}{\sigma^2/(n+\kappa)} }{ \sqrt{ \big(\frac{\nu V(\mu\|\sigma^2)+(n-1)s^2}{\sigma^2}  + \frac{(n^{-1}+\kappa^{-1})^{-1}(\bar{x}+E(\mu\|\sigma^2))^2}{\sigma^2}\big)\big/(n+\nu)} } \Big\| x_1,\dots,x_n \sim t(n+\nu)$

***Conjugate Prior Normal distribution***

- 정규분포의 경우는 외우는것이 좀 힘들어서 약간의 설명을 하겠다. 정규분포의 모수에서 평균은 똑같이 정규분포를 따른다고 가정하고 분산의 역수는 카이제곱분포를 따른다고 가정한다. 즉 아래와 같은 상황을 가정한다. 
\begin{align}
\begin{cases}
\frac{\nu V(\mu\|\sigma^2)}{\sigma^2} \sim  \chi^2(\nu) \\\\ \\
\mu \| \sigma^2 \sim N \big(E(\mu\|\sigma^2), V(\mu\|\sigma^2)\big) \\\\ \\
X_1,\dots,X_n \| \mu, \sigma^2  \sim N(\mu,\sigma^2)
\end{cases}
\end{align}
결국 우리가 관측한 자료 $x_1,\dots,x_n \| \mu,\sigma^2$ 의 분산은 $\sigma^2$ 자체의 값과 $\mu$의 분산 $V(\mu\|\sigma^2)$의 값에 영향을 같이 받게 된다. 예를 들어서 관측된자료 $x_1,\dots,x_n$ 이 있다고 치자. 계산해보니까 $\bar{x}=2$이고 표준편차 $s^2=1$ 이었다고 하자. 하지만 이것은 아래의 경우에 모두 가능한 상황이다. 
\begin{align}
\begin{cases}
\mu \sim N(2,1) \\\\ \\
X_1,\dots,X_n \sim N(\mu, 0),
\end{cases} \quad 
\begin{cases}
\mu \sim N(2,0) \\\\ \\
X_1,\dots,X_n \sim N(\mu,1).
\end{cases}
\end{align}
둘다 다소 극단적이긴 했지만 모든 케이스들은 이러한 두 양근단의 사이일 것이다. 그럼 어떻게 결정을 해야할까? 한 가지 방법은 
\begin{align}
\frac{\sigma^2}{V(\mu\|\sigma^2)}
\end{align}
의 값을 미리 정하는 것이다. 김우철 교수님의 교재에서는 이를 카파로 정의하였다. 즉 
\begin{align}
\kappa:=\frac{\sigma^2}{V(\mu\|\sigma^2)}
\end{align}
이다. 따라서 이 기호를 사용하면 아래와 같이 표현할 수 있다. 
\begin{align}
\begin{cases}
\frac{\nu}{\kappa} \sim  \chi^2(\nu) \\\\ \\
\mu \| \sigma^2 \sim N \big(E(\mu\|\sigma^2), \frac{\sigma^2}{\kappa} \big) \\\\ \\
X_1,\dots,X_n \| \mu, \sigma^2  \sim N(\mu,\sigma^2)
\end{cases}
\end{align}
눈치빠르다면 $\frac{\sigma^2}{\kappa}$ 의 표현을 보고 뭔가 느끼는게 있을 것이다. 계산해보면 알겠지만 $\bar{x}$는 $n$이 커질수록 점점 포스테리어에서 힘을 받는데 $E(\mu\|\sigma^2)$는 $\kappa$가 커질수록 힘을 받는다. 따라서 $\kappa$는 $n$에 대응하는 개념으로 생각할 수 있다. 왜 그럴까? 내가 이해하기로는 $\kappa$를 크게 잡는다는 것은 표본의 분산이 $\mu\|\sigma^2$ 보다 크다고 선입견가지는 것인데 이는 평군의 추정에서 표본의 평균 $\bar{x}$을 믿기 싫다는 의미라고 볼 수 있다. 즉 $\kappa$ 가 클수록 평균을 추정할때 표본평균 $\bar{x}$보다 프라이어의 평균 $E(\mu \|\sigma^2)$을 더 신뢰하겠다는 의도로 해석할 수 있다. 

- 실제로 $\kappa$는 거의 $n$과 비슷하게 생각해도 된다. 모두 $\mu$의 포스테리어는 아래와 같이 계산가능하다. 
\begin{align}
\mu \| \sigma^2, x_1,\dots,x_n \sim N\Big(\frac{n\bar{x}+\kappa E(\mu\|\sigma^2)}{n+\kappa} ,\frac{\sigma^2}{n+\kappa}\Big)
\end{align}
이때 마치 $\kappa$는 샘플평균 $\bar{x}$와 prior mean $E(\mu\|\sigma^2)$ 사이에 적절한 웨이트를 조정하는 역할을 한다. 

- 그렇다면 $\nu$의 역할은 무엇일까? 아래의 포스테리어를 관찰하여 보자. 
\begin{align}
\frac{\nu V(\mu\|\sigma^2) + (n-1)s^2+(n^{-1}+\kappa^{-1})^{-1}\big(\bar{x}-E(\mu\|\sigma^2)\big)^2 }{\sigma^2} \bigg\| x_1,\dots,x_n \sim \chi^2(\nu+n)
\end{align}
위의 식은 (1) prior variance 즉 $V(\mu\|\sigma^2)$ 로만 분산을 구한것과 (2) 샘플 variance 즉 $x_1,\dots,x_n$ 으로만 분산을 계산한것 (3) 프라이어와 표본의 오차를 보정하는 텀으로 혼합되어 있다. 이중에서 $\kappa$는 (3)을 계산하는 가중치를 조절한다. 즉 여기에서 (1),(2)는 variance 와 관련된 항목이고 (3)은 bias와 관련된 항목이다. 여기까지 추론하면 $\nu$의 역할은 명확해진다. 바로 variance를 결정하는 두 항목 
\begin{align}
V(\mu\|\sigma^2), \quad (n-1)s^2
\end{align}
사이의 가중치를 조정하는 역할을 한다. 

- 여기까지 과정을 알면 마지막 t분포는 쉽게 유도할 수 있다. 
\begin{align}
\frac{\frac{\mu-E(\mu\|\sigma^2,x_1,\dots,x_n)}{\sigma^2/(n+\kappa)} }{ \sqrt{ \big(\frac{\nu V(\mu\|\sigma^2)+(n-1)s^2}{\sigma^2}  + \frac{(n^{-1}+\kappa^{-1})^{-1}(\bar{x}+E(\mu\|\sigma^2))^2}{\sigma^2}\big)\big/(n+\nu)} } \Big\| x_1,\dots,x_n \sim t(n+\nu). 
\end{align}


